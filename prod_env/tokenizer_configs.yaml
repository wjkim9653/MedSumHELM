tokenizer_configs:
  - name: meta/llama-3-8b-instruct
    tokenizer_spec:
      class_name: "helm.tokenizers.huggingface_tokenizer.HuggingFaceTokenizer"
      args:
        pretrained_model_name_or_path: meta-llama/Meta-Llama-3.1-8B-Instruct
    prefix_token: "<|begin_of_text|>"
    end_of_text_token: "<|eot_id|>"

  - name: meta/llama-3.2-3b-instruct
    tokenizer_spec:
      class_name: "helm.tokenizers.huggingface_tokenizer.HuggingFaceTokenizer"
      args:
        pretrained_model_name_or_path: meta-llama/Llama-3.2-3B-Instruct
    prefix_token: "<|begin_of_text|>"
    end_of_text_token: "<|eot_id|>"
  
  - name: meta/llama-3.2-1b-instruct
    tokenizer_spec:
      class_name: "helm.tokenizers.huggingface_tokenizer.HuggingFaceTokenizer"
      args:
        pretrained_model_name_or_path: meta-llama/Llama-3.2-1B-Instruct
    prefix_token: "<|begin_of_text|>"
    end_of_text_token: "<|eot_id|>"