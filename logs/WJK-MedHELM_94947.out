2025-08-14 23:24:31,318 INFO     helm_run {
2025-08-14 23:24:32,373 INFO       Reading tokenizer configs from /data/wjkim9653/anaconda3/envs/HELM/lib/python3.10/site-packages/helm/config/tokenizer_configs.yaml...
2025-08-14 23:24:32,536 INFO       Reading model deployments from /data/wjkim9653/anaconda3/envs/HELM/lib/python3.10/site-packages/helm/config/model_deployments.yaml...
2025-08-14 23:24:33,226 INFO       Reading tokenizer configs from prod_env/tokenizer_configs.yaml...
2025-08-14 23:24:33,231 INFO       Reading model deployments from prod_env/model_deployments.yaml...
2025-08-14 23:24:33,337 INFO       Read 10 run entries from run_entries_medhelm_public.conf
2025-08-14 23:24:35,931 INFO       10 entries produced 1 run specs
2025-08-14 23:24:35,932 INFO       run_specs {
2025-08-14 23:24:35,932 INFO         RunSpec(name='aci_bench:model=meta_llama-3.1-8b-instruct,model_deployment=huggingface_llama-3.1-8b-instruct', scenario_spec=ScenarioSpec(class_name='helm.benchmark.scenarios.aci_bench_scenario.ACIBenchScenario', args={}), adapter_spec=AdapterSpec(method='generation', global_prefix='', global_suffix='', instructions='Summarize the conversation to generate a clinical note with four sections:\n1. HISTORY OF PRESENT ILLNESS\n2. PHYSICAL EXAM\n3. RESULTS\n4. ASSESSMENT AND PLAN\n\nThe conversation is:\n', input_prefix='Conversation: ', input_suffix='\n', reference_prefix='A. ', reference_suffix='\n', chain_of_thought_prefix='', chain_of_thought_suffix='\n', output_prefix='Clinical Note: ', output_suffix='\n', instance_prefix='\n', substitutions=[], max_train_instances=0, max_eval_instances=120, num_outputs=1, num_train_trials=1, num_trials=1, sample_train=True, model_deployment='huggingface/llama-3.1-8b-instruct', model='meta/llama-3.1-8b-instruct', temperature=0.0, max_tokens=768, stop_sequences=[], random=None, multi_label=False, image_generation_parameters=None, reeval_parameters=None, eval_splits=None), metric_specs=[MetricSpec(class_name='helm.benchmark.metrics.summarization_metrics.SummarizationMetric', args={'task': 'aci_bench', 'device': 'cuda', 'bertscore_model': 'distilbert-base-uncased', 'rescale_with_baseline': False}), MetricSpec(class_name='helm.benchmark.metrics.basic_metrics.BasicGenerationMetric', args={'names': []}), MetricSpec(class_name='helm.benchmark.metrics.basic_metrics.BasicReferenceMetric', args={}), MetricSpec(class_name='helm.benchmark.metrics.basic_metrics.InstancesPerSplitMetric', args={}), MetricSpec(class_name='helm.benchmark.metrics.aci_bench_metrics.ACIBenchMetric', args={})], data_augmenter_spec=DataAugmenterSpec(perturbation_specs=[], should_augment_train_instances=False, should_include_original_train=False, should_skip_unchanged_train=False, should_augment_eval_instances=False, should_include_original_eval=False, should_skip_unchanged_eval=False, seeds_per_instance=1), groups=['clinical', 'aci_bench'], annotators=[AnnotatorSpec(class_name='helm.benchmark.annotation.aci_bench_annotator.ACIBenchAnnotator', args={})])
2025-08-14 23:24:35,932 INFO       } [0.0s]
2025-08-14 23:24:35,932 INFO       Running in local mode with base path: prod_env
Looking in path: prod_env
2025-08-14 23:24:35,954 INFO       AutoTokenizer: cache_backend_config = BlackHoleCacheBackendConfig()
2025-08-14 23:24:35,954 INFO       AutoClient: file_storage_path = prod_env/cache
2025-08-14 23:24:35,954 INFO       AutoClient: cache_backend_config = BlackHoleCacheBackendConfig()
2025-08-14 23:24:35,954 INFO       AutoTokenizer: cache_backend_config = BlackHoleCacheBackendConfig()
Looking in path: prod_env
2025-08-14 23:24:35,973 INFO       AnnotatorFactory: file_storage_path = prod_env/cache
2025-08-14 23:24:35,973 INFO       AnnotatorFactory: cache_backend_config = BlackHoleCacheBackendConfig()
2025-08-14 23:24:35,976 INFO       Running aci_bench:model=meta_llama-3.1-8b-instruct,model_deployment=huggingface_llama-3.1-8b-instruct {
2025-08-14 23:24:35,979 INFO         scenario.get_instances {
2025-08-14 23:24:35,979 INFO           ensure_file_downloaded {
2025-08-14 23:24:35,980 INFO             Not downloading https://raw.githubusercontent.com/wyim/aci-bench/e75b383172195414a7a68843ec4876e83e5409f7/data/challenge_data_json/train_full.json because benchmark_output/scenarios/aci_bench/aci_bench_train.json already exists
2025-08-14 23:24:35,981 INFO           } [0.002s]
2025-08-14 23:24:35,986 INFO           ensure_file_downloaded {
2025-08-14 23:24:35,988 INFO             Not downloading https://raw.githubusercontent.com/wyim/aci-bench/e75b383172195414a7a68843ec4876e83e5409f7/data/challenge_data_json/clinicalnlp_taskB_test1_full.json because benchmark_output/scenarios/aci_bench/aci_bench_test_1.json already exists
2025-08-14 23:24:35,988 INFO           } [0.002s]
2025-08-14 23:24:35,991 INFO           ensure_file_downloaded {
2025-08-14 23:24:35,993 INFO             Not downloading https://raw.githubusercontent.com/wyim/aci-bench/e75b383172195414a7a68843ec4876e83e5409f7/data/challenge_data_json/clef_taskC_test3_full.json because benchmark_output/scenarios/aci_bench/aci_bench_test_2.json already exists
2025-08-14 23:24:35,993 INFO           } [0.001s]
2025-08-14 23:24:35,996 INFO           ensure_file_downloaded {
2025-08-14 23:24:35,997 INFO             Not downloading https://raw.githubusercontent.com/wyim/aci-bench/e75b383172195414a7a68843ec4876e83e5409f7/data/challenge_data_json/clinicalnlp_taskC_test2_full.json because benchmark_output/scenarios/aci_bench/aci_bench_test_3.json already exists
2025-08-14 23:24:35,998 INFO           } [0.001s]
2025-08-14 23:24:36,001 INFO         } [0.021s]
2025-08-14 23:24:36,002 INFO         187 instances, 67 train instances, 120/120 eval instances
2025-08-14 23:24:36,003 INFO         DataPreprocessor.preprocess {
2025-08-14 23:24:36,003 INFO         } [0.0s]
2025-08-14 23:24:36,005 INFO         GenerationAdapter.adapt {
2025-08-14 23:24:36,006 INFO           187 instances, choosing 0/67 train instances, 120 eval instances
2025-08-14 23:24:36,006 INFO           Adapting with train_trial_index=0 {
2025-08-14 23:24:36,006 INFO             Sampled 0 examples for trial #0.
2025-08-14 23:24:36,006 INFO             Parallelizing computation on 120 items over 4 threads {
2025-08-14 23:24:38,431 INFO               Created cache with config: BlackHoleCacheConfig()
2025-08-14 23:24:38,431 INFO               Loading meta-llama/Llama-3.1-8B-Instruct (kwargs={}) for HELM tokenizer meta/llama-3.1-8b-instruct with Hugging Face Transformers {
2025-08-14 23:24:38,432 INFO                 Created cache with config: BlackHoleCacheConfig()
2025-08-14 23:24:38,432 INFO                 Created cache with config: BlackHoleCacheConfig()
2025-08-14 23:24:38,433 INFO                 Created cache with config: BlackHoleCacheConfig()
2025-08-14 23:24:38,995 INFO               } [0.563s]
2025-08-14 23:24:42,627 INFO             } [6.62s]
2025-08-14 23:24:42,628 INFO             Sample prompts {
2025-08-14 23:24:42,628 INFO               reference index = None, request_mode = None {
2025-08-14 23:24:42,628 INFO                 Summarize the conversation to generate a clinical note with four sections:
2025-08-14 23:24:42,628 INFO                 1. HISTORY OF PRESENT ILLNESS
2025-08-14 23:24:42,628 INFO                 2. PHYSICAL EXAM
2025-08-14 23:24:42,628 INFO                 3. RESULTS
2025-08-14 23:24:42,628 INFO                 4. ASSESSMENT AND PLAN
2025-08-14 23:24:42,628 INFO                 
2025-08-14 23:24:42,628 INFO                 The conversation is:
2025-08-14 23:24:42,628 INFO                 
2025-08-14 23:24:42,628 INFO                 Conversation: Doctor-patient dialogue:
2025-08-14 23:24:42,628 INFO                 
2025-08-14 23:24:42,628 INFO                 [doctor] hi , andrew . how are you ?
2025-08-14 23:24:42,628 INFO                 [patient] hey , good to see you .
2025-08-14 23:24:42,628 INFO                 [doctor] i'm doing well , i'm doing well .
2025-08-14 23:24:42,628 INFO                 [patient] good .
2025-08-14 23:24:42,628 INFO                 [doctor] so , i know the nurse told you about dax . i'd like to tell dax a little bit about you .
2025-08-14 23:24:42,628 INFO                 [patient] sure .
2025-08-14 23:24:42,628 INFO                 [doctor] uh , so , andrew is a 59-year-old male with a past medical history , significant for depression , type two diabetes , and hypertension who presents today with an upper respiratory infection . so , andrew , what's going on ?
2025-08-14 23:24:42,628 INFO                 [patient] yeah . we were doing a bit of work out in the yard in the last week or so and i started to feel really tired , was short of breath . um , we- we're not wearing masks as much at the end of the summer and i think i caught my first cold and i think it just got worse .
2025-08-14 23:24:42,628 INFO                 [doctor] okay . all right . um , now , have you had your covid vaccines ?
2025-08-14 23:24:42,628 INFO                 [patient] yeah , both .
2025-08-14 23:24:42,629 INFO                 [doctor] okay . all right . and , um , do you have any history of any seasonal allergies at all ?
2025-08-14 23:24:42,629 INFO                 [patient] none whatsoever .
2025-08-14 23:24:42,629 INFO                 [doctor] okay . all right . and when you say you're having some shortness of breath , did you feel short of breath walking around or at rest ?
2025-08-14 23:24:42,629 INFO                 [patient] uh , usually , it was lifting or carrying something . we were doing some landscaping , so i was carrying some heavy bags of soil and i , i got really winded . it really surprised me .
2025-08-14 23:24:42,629 INFO                 [doctor] okay . and are you coughing up anything ?
2025-08-14 23:24:42,629 INFO                 [patient] not yet , but i feel like that's next .
2025-08-14 23:24:42,629 INFO                 [doctor] okay . and fevers ?
2025-08-14 23:24:42,629 INFO                 [patient] uh , i felt a little warm , but i , i just thought it was because i was exerting myself .
2025-08-14 23:24:42,629 INFO                 [doctor] okay . all right . and any other symptoms like muscle aches , joint pain , fatigue ?
2025-08-14 23:24:42,629 INFO                 [patient] my elbows hurt quite a bit and my knees were pretty tired . l- like i said , i really felt some tension around my knees , but , uh , i think that was a lot to do with , uh , lifting the bags .
2025-08-14 23:24:42,629 INFO                 [doctor] okay . all right . um , so , you know , how about , how are you doing in terms of your other medical problems , like your depression ? how are you doing with that ? i know we've , you know , talked about not putting you on medication for it because you're on medication for other things . what's going on ?
2025-08-14 23:24:42,629 INFO                 [patient] i- it's been kind of a crazy year and a half . i was a little concerned about that but , for the most part , i've been , been doing well with it . my , my wife got me into barre classes , to help me relax and i think it's working .
2025-08-14 23:24:42,629 INFO                 [doctor] okay . all right , great . and , and in terms of your diabetes , how are you doing watching your , your diet and your sugar intake ?
2025-08-14 23:24:42,629 INFO                 [patient] uh , i've been monitoring my sugar levels while i am going to work during the week . uh , not so , uh , if its saturday or sunday i usually don't remember . uh , the diet's been pretty good for the most part , except for , you know , some house parties and things like that . but , uh , been good for the most part .
2025-08-14 23:24:42,629 INFO                 [doctor] okay and have they been elevated at all since this episode of your-
2025-08-14 23:24:42,629 INFO                 [patient] no .
2025-08-14 23:24:42,629 INFO                 [doctor] okay . and then , how , lastly , for your high blood pressure , have you been monitoring your blood pressures at home ? did you buy the cuff like i suggested ?
2025-08-14 23:24:42,629 INFO                 [patient] uh , same thing . during the while i'm going to work, i'm regular about monitoring it, but if its a saturday or sunday, not so much . but , uh , it's , it's been under control .
2025-08-14 23:24:42,629 INFO                 [doctor] but you're taking your medication ?
2025-08-14 23:24:42,629 INFO                 [patient] yes .
2025-08-14 23:24:42,629 INFO                 [doctor] okay . all right . well , you know , i know that , you know , you've endorsed , you know , the shortness of breath and some joint pain . um , how about any other symptoms ? nausea or vomiting ? diarrhea ?
2025-08-14 23:24:42,629 INFO                 [patient] no .
2025-08-14 23:24:42,629 INFO                 [doctor] anything like that ?
2025-08-14 23:24:42,629 INFO                 [patient] no .
2025-08-14 23:24:42,629 INFO                 [doctor] okay . all right . well , i wan na go ahead and do a quick physical exam , all right ? hey , dragon , show me the vital signs . so , your vital signs here in the office look quite good .
2025-08-14 23:24:42,629 INFO                 [patient] mm-hmm .
2025-08-14 23:24:42,630 INFO                 [doctor] you know , everything's looking normal , you do n't have a fever , which is really good . um , i'm just gon na go ahead and listen to your heart and your lungs and , kind of , i'll let you know what i hear , okay ?
2025-08-14 23:24:42,630 INFO                 [patient] sure .
2025-08-14 23:24:42,630 INFO                 [doctor] okay . so , on your physical exam , you know , your heart sounds nice and strong . your lungs , you do have scattered ronchi bilaterally on your lung exam . uh , it clears with cough . um , i do notice a little bit of , um , some edema of your lower extremities and you do have some pain to palpation of your elbows bilaterally . um , so , let's go ahead , i want to look at some of your results , okay ?
2025-08-14 23:24:42,630 INFO                 [patient] mm-hmm .
2025-08-14 23:24:42,630 INFO                 [doctor] hey , dragon . show me the chest x-ray .
2025-08-14 23:24:42,630 INFO                 [doctor] so , i reviewed the results of your chest x-ray and everything looks good . there's no airspace disease , there's no pneumonia , so that's all very , very good , okay ?
2025-08-14 23:24:42,630 INFO                 [patient] good .
2025-08-14 23:24:42,630 INFO                 [doctor] hey , dragon . show me the diabetic labs .
2025-08-14 23:24:42,630 INFO                 [doctor] and here , looking at your diabetic labs , you know , your hemoglobin a1c is a little elevated at eight .
2025-08-14 23:24:42,630 INFO                 [patient] mm-hmm .
2025-08-14 23:24:42,630 INFO                 [doctor] i'd like to see that a little bit better , around six or seven , if possible .
2025-08-14 23:24:42,630 INFO                 [patient] mm-hmm .
2025-08-14 23:24:42,630 INFO                 [doctor] um , so let's talk a little bit about my assessment and my plan for you .
2025-08-14 23:24:42,630 INFO                 [patient] mm-hmm .
2025-08-14 23:24:42,630 INFO                 [doctor] so , for your first problem , this upper respiratory infection , i believe you , you have a viral syndrome , okay ? we'll go ahead and we'll send a covid test , just to make sure that you do n't have covid .
2025-08-14 23:24:42,630 INFO                 [patient] mm-hmm .
2025-08-14 23:24:42,630 INFO                 [doctor] uh , but overall , i think that , um , you know , this will resolve in a couple of days . i do n't think you have covid , you do n't have any exposures , that type of thing .
2025-08-14 23:24:42,630 INFO                 [patient] mm-hmm .
2025-08-14 23:24:42,630 INFO                 [doctor] so , i think that this will improve . i'll give you some robitussin for your cough and i would encourage you take some ibuprofen , tylenol for any fever , okay ?
2025-08-14 23:24:42,630 INFO                 [patient] you got it .
2025-08-14 23:24:42,630 INFO                 [doctor] for your next problem , your depression , you know , it sounds like you're doing well with that , but again , i'm happy to start on a med- , a medical regiment or ...
2025-08-14 23:24:42,630 INFO                 [patient] mm-hmm .
2025-08-14 23:24:42,630 INFO                 [doctor] . refer you to psychotherapy , if you think that that would be helpful .
2025-08-14 23:24:42,630 INFO                 [patient] mm-hmm .
2025-08-14 23:24:42,630 INFO                 [doctor] would you like that ?
2025-08-14 23:24:42,630 INFO                 [patient] u- u- um , maybe not necessarily . maybe in a , uh , few months we'll check on that .
2025-08-14 23:24:42,631 INFO                 [doctor] okay . all right .
2025-08-14 23:24:42,631 INFO                 [doctor] for your third problem , your type two diabetes , i want to go ahead and increase your metformin to 1000 milligrams , twice daily .
2025-08-14 23:24:42,631 INFO                 [patient] mm-hmm .
2025-08-14 23:24:42,631 INFO                 [doctor] and i'm gon na get an- another hemoglobin a1c in four months , okay ?
2025-08-14 23:24:42,631 INFO                 [patient] okay , sure .
2025-08-14 23:24:42,631 INFO                 [doctor] hey , dragon . order a hemoglobin a1c .
2025-08-14 23:24:42,631 INFO                 [doctor] and lastly , for your high blood pressure , it looks like you're doing a really good job managing that . i want to go ahead and continue you on the , um , lisinopril , 20 milligrams a day .
2025-08-14 23:24:42,631 INFO                 [patient] mm-hmm .
2025-08-14 23:24:42,631 INFO                 [doctor] and i'm gon na go ahead and order a lipid panel , okay ?
2025-08-14 23:24:42,631 INFO                 [patient] sure .
2025-08-14 23:24:42,631 INFO                 [doctor] do you need a refill of the lisinopril ?
2025-08-14 23:24:42,631 INFO                 [patient] actually , i do .
2025-08-14 23:24:42,631 INFO                 [doctor] okay . hey , dragon . order lisinopril , 20 milligrams daily .
2025-08-14 23:24:42,631 INFO                 [doctor] so , the nurse will be in , she'll help you , uh , make a follow-up appointment with me . i want to see you again in about four months .
2025-08-14 23:24:42,631 INFO                 [patient] okay .
2025-08-14 23:24:42,631 INFO                 [doctor] let me know if your symptoms worsen and we can talk more about it , okay ?
2025-08-14 23:24:42,631 INFO                 [patient] you got it .
2025-08-14 23:24:42,631 INFO                 [doctor] all right . hey , dragon . finalize the note .
2025-08-14 23:24:42,631 INFO                 Clinical Note:
2025-08-14 23:24:42,631 INFO               } [0.003s]
2025-08-14 23:24:42,631 INFO             } [0.003s]
2025-08-14 23:24:42,631 INFO           } [6.625s]
2025-08-14 23:24:42,631 INFO           120 requests
2025-08-14 23:24:42,631 INFO         } [6.625s]
2025-08-14 23:24:42,632 INFO         Executor.execute {
2025-08-14 23:24:42,632 INFO           Parallelizing computation on 120 items over 4 threads {
2025-08-14 23:24:42,651 INFO             Created cache with config: BlackHoleCacheConfig()
2025-08-14 23:24:42,652 INFO             Created cache with config: BlackHoleCacheConfig()
2025-08-14 23:24:42,652 INFO             Created cache with config: BlackHoleCacheConfig()
2025-08-14 23:24:42,652 INFO             Created cache with config: BlackHoleCacheConfig()
2025-08-14 23:24:42,652 INFO             Created cache with config: BlackHoleCacheConfig()
2025-08-14 23:24:42,652 INFO             Created cache with config: BlackHoleCacheConfig()
2025-08-14 23:24:42,653 WARNING          Automatically set `apply_chat_template` to True based on whether the tokenizer has a chat template. If this is incorrect, please explicitly set `apply_chat_template`.
2025-08-14 23:24:42,653 WARNING          Automatically set `apply_chat_template` to True based on whether the tokenizer has a chat template. If this is incorrect, please explicitly set `apply_chat_template`.
2025-08-14 23:24:42,653 WARNING          Automatically set `apply_chat_template` to True based on whether the tokenizer has a chat template. If this is incorrect, please explicitly set `apply_chat_template`.
2025-08-14 23:24:42,653 WARNING          Automatically set `apply_chat_template` to True based on whether the tokenizer has a chat template. If this is incorrect, please explicitly set `apply_chat_template`.
2025-08-14 23:24:42,689 INFO             Loading meta-llama/Llama-3.1-8B-Instruct (kwargs={'torch_dtype': 'float16'}) for HELM model meta/llama-3.1-8b-instruct with Hugging Face Transformers {
2025-08-14 23:24:42,690 INFO               Hugging Face device set to "cuda:0" because CUDA is available.
2025-08-14 23:24:42,690 INFO               Loading Hugging Face model meta-llama/Llama-3.1-8B-Instruct {
2025-08-14 23:25:00,319 INFO               } [17.629s]
2025-08-14 23:25:00,320 INFO             } [17.629s]
2025-08-14 23:25:59,850 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:26:11,238 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:26:16,558 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:26:27,892 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:26:57,115 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:27:16,463 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:27:36,618 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:27:44,298 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:27:55,956 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:28:25,886 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:28:49,528 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:28:58,019 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:29:08,099 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:29:57,409 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:30:01,211 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:30:10,488 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:30:18,116 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:31:05,181 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:31:07,908 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:31:28,795 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:31:33,462 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:32:19,857 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:32:23,708 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:32:42,383 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:32:52,484 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:33:38,513 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:33:40,941 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:33:51,732 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:34:05,494 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:35:04,583 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:35:07,620 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:35:11,606 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:35:18,368 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:36:18,973 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:36:23,135 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:36:29,590 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:36:38,148 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:37:39,962 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:37:41,492 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:37:44,499 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:37:48,536 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:38:38,962 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:38:52,607 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:38:56,952 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:38:57,916 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:39:46,410 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:39:51,364 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:39:52,788 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:40:10,207 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:41:05,199 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:41:05,258 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:41:23,695 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:41:34,338 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:42:26,363 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:42:31,972 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:42:42,945 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:42:51,917 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:43:42,471 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:43:43,598 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:43:51,239 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:44:07,194 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:45:04,163 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:45:04,562 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:45:12,114 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:45:28,954 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:46:06,206 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:46:27,644 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:46:35,132 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:46:50,142 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:47:37,079 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:47:47,753 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:48:01,309 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:48:07,065 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:48:51,137 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:48:55,528 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:49:14,700 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:49:24,130 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:49:58,392 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:50:14,270 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:50:29,746 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:50:36,538 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:51:05,024 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:51:19,495 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:51:26,153 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:51:36,334 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:52:18,844 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:52:35,571 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:52:42,938 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:52:57,589 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:53:31,691 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:54:00,844 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:54:03,764 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:54:24,700 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:55:07,147 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:55:11,359 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:55:30,368 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:55:53,501 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:56:34,829 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:56:40,038 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:56:44,683 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:57:08,817 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:57:53,733 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:58:04,741 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:58:22,315 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:58:36,751 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:59:04,037 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:59:17,607 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-14 23:59:34,869 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-15 00:00:02,443 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-15 00:00:27,488 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-15 00:00:36,705 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-15 00:00:37,642 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-15 00:01:17,583 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-15 00:01:41,806 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-15 00:01:44,330 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-15 00:02:07,457 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-15 00:02:52,885 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-15 00:02:56,660 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-15 00:02:58,655 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-15 00:03:06,262 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-15 00:03:06,262 INFO           } [38m23.63s]
2025-08-15 00:03:06,263 INFO           Processed 120 requests
2025-08-15 00:03:06,263 INFO         } [38m23.631s]
2025-08-15 00:03:06,264 INFO         AnnotationExecutor.execute {
2025-08-15 00:03:06,272 INFO           AutoTokenizer: cache_backend_config = BlackHoleCacheBackendConfig()
2025-08-15 00:03:06,272 INFO           AutoClient: file_storage_path = prod_env/cache
2025-08-15 00:03:06,272 INFO           AutoClient: cache_backend_config = BlackHoleCacheBackendConfig()
2025-08-15 00:03:06,273 INFO           Parallelizing computation on 120 items over 4 threads {
2025-08-15 00:03:07,384 INFO             Created cache with config: BlackHoleCacheConfig()
2025-08-15 00:03:07,385 INFO             Using host_organization api key defined in credentials.conf: openaiApiKey
2025-08-15 00:03:07,385 INFO             Created cache with config: BlackHoleCacheConfig()
2025-08-15 00:03:07,386 INFO             Created cache with config: BlackHoleCacheConfig()
2025-08-15 00:03:07,386 INFO             Using host_organization api key defined in credentials.conf: openaiApiKey
2025-08-15 00:03:07,386 INFO             Created cache with config: BlackHoleCacheConfig()
2025-08-15 00:03:07,387 INFO             Created cache with config: BlackHoleCacheConfig()
2025-08-15 00:03:07,388 INFO             Created cache with config: BlackHoleCacheConfig()
2025-08-15 00:03:07,388 INFO             Using host_organization api key defined in credentials.conf: openaiApiKey
2025-08-15 00:03:07,388 INFO             Using host_organization api key defined in credentials.conf: openaiApiKey
2025-08-15 00:03:07,389 INFO             Created cache with config: BlackHoleCacheConfig()
2025-08-15 00:03:07,389 INFO             Created cache with config: BlackHoleCacheConfig()
2025-08-15 00:03:42,223 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:03:45,000 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:03:49,821 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:03:54,265 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:04:14,619 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:04:22,507 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:04:25,569 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:04:38,121 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:04:58,834 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:05:00,396 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:05:05,452 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:05:34,146 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:05:45,798 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:05:47,550 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:05:53,857 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:06:22,883 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:06:25,310 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:06:54,568 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:06:57,853 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:07:08,305 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:07:19,144 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:07:31,609 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:07:59,205 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:08:03,389 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:08:08,999 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:08:11,276 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:08:42,648 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:08:58,504 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:09:00,954 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:09:11,038 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:09:39,708 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:09:44,705 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:09:57,480 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:09:59,041 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:10:31,585 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:10:32,281 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:10:45,401 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:10:49,526 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:11:22,337 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:11:24,777 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:11:30,007 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:11:33,952 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:12:05,701 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:12:18,691 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:12:32,235 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:12:32,834 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:12:40,228 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:12:57,811 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:13:03,494 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:13:06,282 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:13:37,578 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:13:38,102 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:13:54,145 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:14:00,616 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:14:08,471 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:14:33,383 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:14:41,650 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:14:46,466 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:15:03,519 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:15:04,246 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:15:15,089 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:15:43,883 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:15:44,263 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:15:55,240 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:15:59,800 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:16:29,193 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:16:36,978 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:16:39,316 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:16:45,275 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:17:11,042 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:17:18,532 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:17:20,190 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:17:34,495 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:17:41,212 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:17:51,168 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:18:01,132 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:18:16,928 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:18:16,987 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:18:26,220 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:18:37,815 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:18:38,458 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:18:59,100 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:18:59,154 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:19:05,888 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:19:09,091 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:19:43,737 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:19:44,588 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:19:46,614 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:19:47,208 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:20:25,030 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:20:30,599 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:20:34,826 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:20:46,845 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:21:07,462 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:21:26,943 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:21:39,986 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:21:40,495 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:21:53,593 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:22:18,805 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:22:20,526 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:22:39,397 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:23:04,881 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:23:07,831 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:23:22,982 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:23:24,139 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:23:42,304 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:23:50,734 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:24:06,922 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:24:17,251 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:24:24,226 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:24:40,522 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:24:52,564 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:25:00,976 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:25:17,038 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:25:18,991 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:25:45,805 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:26:02,033 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:26:07,080 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:26:21,915 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:26:28,265 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-15 00:26:28,266 INFO           } [23m21.993s]
2025-08-15 00:26:28,266 INFO           Annotated 120 requests
2025-08-15 00:26:28,267 INFO         } [23m22.002s]
2025-08-15 00:26:32,583 INFO         5 metrics {
2025-08-15 00:26:32,583 INFO           <helm.benchmark.metrics.summarization_metrics.SummarizationMetric object at 0x7fb15552d810> {
2025-08-15 00:26:32,583 INFO             Setting parallelism from 4 to 1, since evaluating faithfulness with parallelism > 1 errors.
2025-08-15 00:26:32,583 INFO             Parallelizing computation on 120 items over 1 threads {
2025-08-15 00:26:32,583 INFO               ensure_file_downloaded {
2025-08-15 00:26:32,585 INFO                 Not downloading https://storage.googleapis.com/crfm-helm-public/source_datasets/metrics/summarization_metrics/qafacteval.pk because benchmark_output/runs/my-medhelm-suite/eval_cache/qafacteval.pk already exists
2025-08-15 00:26:32,586 INFO               } [0.002s]
2025-08-15 00:33:59,086 INFO             } [7m26.503s]
2025-08-15 00:33:59,184 INFO           } [7m26.6s]
2025-08-15 00:33:59,184 INFO           BasicMetric() {
2025-08-15 00:33:59,184 INFO             Parallelizing computation on 120 items over 4 threads {
2025-08-15 00:34:00,072 INFO             } [0.887s]
2025-08-15 00:34:00,238 INFO           } [1.054s]
2025-08-15 00:34:00,238 INFO           BasicReferenceMetric {
2025-08-15 00:34:00,238 INFO             Parallelizing computation on 120 items over 4 threads {
2025-08-15 00:34:00,242 INFO             } [0.004s]
2025-08-15 00:34:00,243 INFO           } [0.004s]
2025-08-15 00:34:00,243 INFO           <helm.benchmark.metrics.basic_metrics.InstancesPerSplitMetric object at 0x7fb098af2980> {
2025-08-15 00:34:00,243 INFO           } [0.0s]
2025-08-15 00:34:00,243 INFO           <helm.benchmark.metrics.aci_bench_metrics.ACIBenchMetric object at 0x7fb098af2a10> {
2025-08-15 00:34:00,244 INFO             Parallelizing computation on 120 items over 4 threads {
2025-08-15 00:34:00,251 INFO             } [0.006s]
2025-08-15 00:34:00,260 INFO           } [0.016s]
2025-08-15 00:34:00,260 INFO         } [7m27.677s]
2025-08-15 00:34:00,260 INFO         Generated 90 stats.
2025-08-15 00:34:00,261 INFO         Writing 2530 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=meta_llama-3.1-8b-instruct,model_deployment=huggingface_llama-3.1-8b-instruct/run_spec.json
2025-08-15 00:34:00,357 INFO         Writing 567 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=meta_llama-3.1-8b-instruct,model_deployment=huggingface_llama-3.1-8b-instruct/scenario.json
2025-08-15 00:34:01,240 INFO         Writing 9144196 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=meta_llama-3.1-8b-instruct,model_deployment=huggingface_llama-3.1-8b-instruct/scenario_state.json
2025-08-15 00:34:01,284 INFO         Writing 33115 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=meta_llama-3.1-8b-instruct,model_deployment=huggingface_llama-3.1-8b-instruct/stats.json
2025-08-15 00:34:01,503 INFO         Writing 1139414 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=meta_llama-3.1-8b-instruct,model_deployment=huggingface_llama-3.1-8b-instruct/per_instance_stats.json
2025-08-15 00:34:01,508 INFO         CacheStats.print_status {
2025-08-15 00:34:01,508 INFO           disabled_cache: 840 queries, 840 computes
2025-08-15 00:34:01,508 INFO         } [0.0s]
2025-08-15 00:34:01,508 INFO       } [1h9m25.531s]
2025-08-15 00:34:01,508 INFO       Done.
2025-08-15 00:34:01,508 INFO     } [1h9m30.189s]
2025-08-15 00:34:09,273 INFO     summarize: summarize {
2025-08-15 00:34:10,384 INFO       Reading tokenizer configs from /data/wjkim9653/anaconda3/envs/HELM/lib/python3.10/site-packages/helm/config/tokenizer_configs.yaml...
2025-08-15 00:34:10,551 INFO       Reading model deployments from /data/wjkim9653/anaconda3/envs/HELM/lib/python3.10/site-packages/helm/config/model_deployments.yaml...
2025-08-15 00:34:11,362 INFO       Reading tokenizer configs from prod_env/tokenizer_configs.yaml...
2025-08-15 00:34:11,367 INFO       Reading model deployments from prod_env/model_deployments.yaml...
2025-08-15 00:34:11,385 INFO       Reading schema file schema_medhelm.yaml...
2025-08-15 00:34:11,647 WARNING    benchmark_output doesn't have run_spec.json or stats.json, skipping
2025-08-15 00:34:11,647 INFO       Summarizer.check_metrics_defined {
2025-08-15 00:34:11,648 INFO       } [0.0s]
2025-08-15 00:34:11,648 INFO       Parallelizing computation on 9 items over 8 threads {
2025-08-15 00:34:11,648 INFO         write_run_display_json {
2025-08-15 00:34:11,649 INFO           write_run_display_json {
2025-08-15 00:34:11,649 INFO             write_run_display_json {
2025-08-15 00:34:11,649 INFO             write_run_display_json {
2025-08-15 00:34:11,650 INFO               write_run_display_json {
2025-08-15 00:34:11,650 INFO                 write_run_display_json {
2025-08-15 00:34:11,651 INFO                     write_run_display_json {
2025-08-15 00:34:11,651 INFO                       write_run_display_json {
2025-08-15 00:34:12,965 INFO                         Writing 83790 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=meta_llama-3.2-1b-instruct,model_deployment=huggingface_llama-3.2-1b-instruct/instances.json
2025-08-15 00:34:13,193 INFO                         Writing 139464 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=meta_llama-3.2-1b-instruct,model_deployment=huggingface_llama-3.2-1b-instruct/display_predictions.json
2025-08-15 00:34:13,445 INFO                         Writing 63533 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=meta_llama-3.2-1b-instruct,model_deployment=huggingface_llama-3.2-1b-instruct/display_requests.json
2025-08-15 00:34:13,804 INFO                       } [2.152s]
2025-08-15 00:34:13,810 INFO                       write_run_display_json {
2025-08-15 00:34:13,892 INFO                         Writing 1160506 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=anthropic_claude-3-7-sonnet-20250219,model_deployment=anthropic_claude-3-7-sonnet-20250219/instances.json
2025-08-15 00:34:14,034 INFO                         Writing 1160506 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=openai_gpt-4.1-2025-04-14,model_deployment=openai_gpt-4.1-2025-04-14/instances.json
2025-08-15 00:34:14,049 INFO                         Writing 1160506 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=meta_llama-3.1-8b-instruct,model_deployment=huggingface_llama-3.1-8b-instruct/instances.json
2025-08-15 00:34:14,075 INFO                         Writing 1160506 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=meta_llama-3.2-3b-instruct,model_deployment=huggingface_llama-3.2-3b-instruct/instances.json
2025-08-15 00:34:14,227 INFO                         Writing 2159106 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=openai_gpt-4.1-2025-04-14,model_deployment=openai_gpt-4.1-2025-04-14/display_predictions.json
2025-08-15 00:34:14,255 INFO                         Writing 2050849 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=meta_llama-3.2-3b-instruct,model_deployment=huggingface_llama-3.2-3b-instruct/display_predictions.json
2025-08-15 00:34:14,280 INFO                         Writing 2090760 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=anthropic_claude-3-7-sonnet-20250219,model_deployment=anthropic_claude-3-7-sonnet-20250219/display_predictions.json
2025-08-15 00:34:14,323 INFO                         Writing 2094624 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=meta_llama-3.1-8b-instruct,model_deployment=huggingface_llama-3.1-8b-instruct/display_predictions.json
2025-08-15 00:34:14,345 INFO                         Writing 1160506 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=meta_llama-3.3-70b-instruct-turbo,model_deployment=together_llama-3.3-70b-instruct-turbo/instances.json
2025-08-15 00:34:14,399 INFO                         Writing 884238 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=meta_llama-3.2-3b-instruct,model_deployment=huggingface_llama-3.2-3b-instruct/display_requests.json
2025-08-15 00:34:14,445 INFO                         Writing 884238 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=meta_llama-3.1-8b-instruct,model_deployment=huggingface_llama-3.1-8b-instruct/display_requests.json
2025-08-15 00:34:14,456 INFO                         Writing 883158 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=openai_gpt-4.1-2025-04-14,model_deployment=openai_gpt-4.1-2025-04-14/display_requests.json
2025-08-15 00:34:14,474 INFO                         Writing 1160506 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=openai_gpt-4.1-nano-2025-04-14,model_deployment=openai_gpt-4.1-nano-2025-04-14/instances.json
2025-08-15 00:34:14,487 INFO                         Writing 885798 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=anthropic_claude-3-7-sonnet-20250219,model_deployment=anthropic_claude-3-7-sonnet-20250219/display_requests.json
2025-08-15 00:34:14,492 INFO                         Writing 1160506 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=openai_gpt-4.1-mini-2025-04-14,model_deployment=openai_gpt-4.1-mini-2025-04-14/instances.json
2025-08-15 00:34:14,522 INFO                         Writing 1160506 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:num_output_tokens=4000,model=deepseek-ai_deepseek-r1-0528,model_deployment=together_deepseek-r1-0528/instances.json
2025-08-15 00:34:14,535 INFO                         Writing 2085405 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=meta_llama-3.3-70b-instruct-turbo,model_deployment=together_llama-3.3-70b-instruct-turbo/display_predictions.json
2025-08-15 00:34:14,551 INFO                       } [0.691s]
2025-08-15 00:34:14,551 INFO                     } [2.899s]
2025-08-15 00:34:14,593 INFO                   } [2.942s]
2025-08-15 00:34:14,597 INFO                   Writing 885558 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=meta_llama-3.3-70b-instruct-turbo,model_deployment=together_llama-3.3-70b-instruct-turbo/display_requests.json
2025-08-15 00:34:14,597 INFO                 } [2.946s]
2025-08-15 00:34:14,645 INFO                 Writing 2118401 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=openai_gpt-4.1-nano-2025-04-14,model_deployment=openai_gpt-4.1-nano-2025-04-14/display_predictions.json
2025-08-15 00:34:14,648 INFO                 Writing 2112708 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=openai_gpt-4.1-mini-2025-04-14,model_deployment=openai_gpt-4.1-mini-2025-04-14/display_predictions.json
2025-08-15 00:34:14,652 INFO                 Writing 2489709 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:num_output_tokens=4000,model=deepseek-ai_deepseek-r1-0528,model_deployment=together_deepseek-r1-0528/display_predictions.json
2025-08-15 00:34:14,666 INFO               } [3.015s]
2025-08-15 00:34:14,692 INFO               Writing 884358 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=openai_gpt-4.1-mini-2025-04-14,model_deployment=openai_gpt-4.1-mini-2025-04-14/display_requests.json
2025-08-15 00:34:14,696 INFO               Writing 883638 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:num_output_tokens=4000,model=deepseek-ai_deepseek-r1-0528,model_deployment=together_deepseek-r1-0528/display_requests.json
2025-08-15 00:34:14,700 INFO               Writing 884358 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=openai_gpt-4.1-nano-2025-04-14,model_deployment=openai_gpt-4.1-nano-2025-04-14/display_requests.json
2025-08-15 00:34:14,721 INFO             } [3.071s]
2025-08-15 00:34:14,724 INFO           } [3.075s]
2025-08-15 00:34:14,724 INFO         } [3.075s]
2025-08-15 00:34:14,725 INFO       } [3.077s]
2025-08-15 00:34:14,734 INFO       Writing 83175 characters to benchmark_output/runs/my-medhelm-suite/schema.json
2025-08-15 00:34:14,736 INFO       Summarizer.write_executive_summary {
2025-08-15 00:34:14,736 INFO         Writing 99 characters to benchmark_output/runs/my-medhelm-suite/summary.json
2025-08-15 00:34:14,738 INFO       } [0.002s]
2025-08-15 00:34:14,802 INFO       Writing 377523 characters to benchmark_output/runs/my-medhelm-suite/runs.json
2025-08-15 00:34:14,808 INFO       Writing 24347 characters to benchmark_output/runs/my-medhelm-suite/run_specs.json
2025-08-15 00:34:14,809 INFO       Writing 1107 characters to benchmark_output/runs/my-medhelm-suite/runs_to_run_suites.json
2025-08-15 00:34:14,810 WARNING    group clinical mentioned in run spec aci_bench:model=anthropic_claude-3-7-sonnet-20250219,model_deployment=anthropic_claude-3-7-sonnet-20250219 but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:14,810 WARNING    group clinical mentioned in run spec aci_bench:model=meta_llama-3.1-8b-instruct,model_deployment=huggingface_llama-3.1-8b-instruct but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:14,810 WARNING    group clinical mentioned in run spec aci_bench:model=meta_llama-3.2-1b-instruct,model_deployment=huggingface_llama-3.2-1b-instruct but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:14,810 WARNING    group clinical mentioned in run spec aci_bench:model=meta_llama-3.2-3b-instruct,model_deployment=huggingface_llama-3.2-3b-instruct but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:14,810 WARNING    group clinical mentioned in run spec aci_bench:model=meta_llama-3.3-70b-instruct-turbo,model_deployment=together_llama-3.3-70b-instruct-turbo but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:14,810 WARNING    group clinical mentioned in run spec aci_bench:model=openai_gpt-4.1-2025-04-14,model_deployment=openai_gpt-4.1-2025-04-14 but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:14,811 WARNING    group clinical mentioned in run spec aci_bench:model=openai_gpt-4.1-mini-2025-04-14,model_deployment=openai_gpt-4.1-mini-2025-04-14 but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:14,811 WARNING    group clinical mentioned in run spec aci_bench:model=openai_gpt-4.1-nano-2025-04-14,model_deployment=openai_gpt-4.1-nano-2025-04-14 but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:14,811 WARNING    group clinical mentioned in run spec aci_bench:num_output_tokens=4000,model=deepseek-ai_deepseek-r1-0528,model_deployment=together_deepseek-r1-0528 but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:14,811 WARNING    group clinical mentioned in run spec aci_bench:model=anthropic_claude-3-7-sonnet-20250219,model_deployment=anthropic_claude-3-7-sonnet-20250219 but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:14,812 WARNING    group clinical mentioned in run spec aci_bench:model=meta_llama-3.1-8b-instruct,model_deployment=huggingface_llama-3.1-8b-instruct but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:14,812 WARNING    group clinical mentioned in run spec aci_bench:model=meta_llama-3.2-1b-instruct,model_deployment=huggingface_llama-3.2-1b-instruct but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:14,812 WARNING    group clinical mentioned in run spec aci_bench:model=meta_llama-3.2-3b-instruct,model_deployment=huggingface_llama-3.2-3b-instruct but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:14,812 WARNING    group clinical mentioned in run spec aci_bench:model=meta_llama-3.3-70b-instruct-turbo,model_deployment=together_llama-3.3-70b-instruct-turbo but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:14,812 WARNING    group clinical mentioned in run spec aci_bench:model=openai_gpt-4.1-2025-04-14,model_deployment=openai_gpt-4.1-2025-04-14 but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:14,812 WARNING    group clinical mentioned in run spec aci_bench:model=openai_gpt-4.1-mini-2025-04-14,model_deployment=openai_gpt-4.1-mini-2025-04-14 but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:14,812 WARNING    group clinical mentioned in run spec aci_bench:model=openai_gpt-4.1-nano-2025-04-14,model_deployment=openai_gpt-4.1-nano-2025-04-14 but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:14,812 WARNING    group clinical mentioned in run spec aci_bench:num_output_tokens=4000,model=deepseek-ai_deepseek-r1-0528,model_deployment=together_deepseek-r1-0528 but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:14,813 WARNING    group clinical mentioned in run spec aci_bench:model=anthropic_claude-3-7-sonnet-20250219,model_deployment=anthropic_claude-3-7-sonnet-20250219 but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:14,814 WARNING    group clinical mentioned in run spec aci_bench:model=meta_llama-3.1-8b-instruct,model_deployment=huggingface_llama-3.1-8b-instruct but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:14,814 WARNING    group clinical mentioned in run spec aci_bench:model=meta_llama-3.2-1b-instruct,model_deployment=huggingface_llama-3.2-1b-instruct but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:14,814 WARNING    group clinical mentioned in run spec aci_bench:model=meta_llama-3.2-3b-instruct,model_deployment=huggingface_llama-3.2-3b-instruct but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:14,814 WARNING    group clinical mentioned in run spec aci_bench:model=meta_llama-3.3-70b-instruct-turbo,model_deployment=together_llama-3.3-70b-instruct-turbo but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:14,814 WARNING    group clinical mentioned in run spec aci_bench:model=openai_gpt-4.1-2025-04-14,model_deployment=openai_gpt-4.1-2025-04-14 but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:14,814 WARNING    group clinical mentioned in run spec aci_bench:model=openai_gpt-4.1-mini-2025-04-14,model_deployment=openai_gpt-4.1-mini-2025-04-14 but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:14,814 WARNING    group clinical mentioned in run spec aci_bench:model=openai_gpt-4.1-nano-2025-04-14,model_deployment=openai_gpt-4.1-nano-2025-04-14 but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:14,814 WARNING    group clinical mentioned in run spec aci_bench:num_output_tokens=4000,model=deepseek-ai_deepseek-r1-0528,model_deployment=together_deepseek-r1-0528 but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:14,825 INFO       Writing 41609 characters to benchmark_output/runs/my-medhelm-suite/groups.json
2025-08-15 00:34:14,827 INFO       Writing 24387 characters to benchmark_output/runs/my-medhelm-suite/groups_metadata.json
2025-08-15 00:34:14,828 WARNING    group clinical mentioned in run spec aci_bench:model=anthropic_claude-3-7-sonnet-20250219,model_deployment=anthropic_claude-3-7-sonnet-20250219 but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:14,829 WARNING    group clinical mentioned in run spec aci_bench:model=meta_llama-3.1-8b-instruct,model_deployment=huggingface_llama-3.1-8b-instruct but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:14,829 WARNING    group clinical mentioned in run spec aci_bench:model=meta_llama-3.2-1b-instruct,model_deployment=huggingface_llama-3.2-1b-instruct but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:14,829 WARNING    group clinical mentioned in run spec aci_bench:model=meta_llama-3.2-3b-instruct,model_deployment=huggingface_llama-3.2-3b-instruct but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:14,829 WARNING    group clinical mentioned in run spec aci_bench:model=meta_llama-3.3-70b-instruct-turbo,model_deployment=together_llama-3.3-70b-instruct-turbo but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:14,829 WARNING    group clinical mentioned in run spec aci_bench:model=openai_gpt-4.1-2025-04-14,model_deployment=openai_gpt-4.1-2025-04-14 but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:14,829 WARNING    group clinical mentioned in run spec aci_bench:model=openai_gpt-4.1-mini-2025-04-14,model_deployment=openai_gpt-4.1-mini-2025-04-14 but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:14,829 WARNING    group clinical mentioned in run spec aci_bench:model=openai_gpt-4.1-nano-2025-04-14,model_deployment=openai_gpt-4.1-nano-2025-04-14 but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:14,829 WARNING    group clinical mentioned in run spec aci_bench:num_output_tokens=4000,model=deepseek-ai_deepseek-r1-0528,model_deployment=together_deepseek-r1-0528 but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:15,219 INFO       Writing 761 characters to benchmark_output/runs/my-medhelm-suite/groups/latex/medhelm_scenarios_accuracy.tex
2025-08-15 00:34:15,231 INFO       Writing 58154 characters to benchmark_output/runs/my-medhelm-suite/groups/json/medhelm_scenarios_accuracy.json
2025-08-15 00:34:15,232 INFO       Writing 784 characters to benchmark_output/runs/my-medhelm-suite/groups/latex/medhelm_scenarios_efficiency.tex
2025-08-15 00:34:15,244 INFO       Writing 61050 characters to benchmark_output/runs/my-medhelm-suite/groups/json/medhelm_scenarios_efficiency.json
2025-08-15 00:34:15,246 INFO       Writing 1072 characters to benchmark_output/runs/my-medhelm-suite/groups/latex/medhelm_scenarios_general_information.tex
2025-08-15 00:34:15,294 INFO       Writing 266963 characters to benchmark_output/runs/my-medhelm-suite/groups/json/medhelm_scenarios_general_information.json
2025-08-15 00:34:15,367 INFO       Writing 410971 characters to benchmark_output/runs/my-medhelm-suite/groups/medhelm_scenarios.json
2025-08-15 00:34:15,370 WARNING    group clinical mentioned in run spec aci_bench:model=anthropic_claude-3-7-sonnet-20250219,model_deployment=anthropic_claude-3-7-sonnet-20250219 but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:15,370 WARNING    group clinical mentioned in run spec aci_bench:model=meta_llama-3.1-8b-instruct,model_deployment=huggingface_llama-3.1-8b-instruct but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:15,370 WARNING    group clinical mentioned in run spec aci_bench:model=meta_llama-3.2-1b-instruct,model_deployment=huggingface_llama-3.2-1b-instruct but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:15,370 WARNING    group clinical mentioned in run spec aci_bench:model=meta_llama-3.2-3b-instruct,model_deployment=huggingface_llama-3.2-3b-instruct but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:15,370 WARNING    group clinical mentioned in run spec aci_bench:model=meta_llama-3.3-70b-instruct-turbo,model_deployment=together_llama-3.3-70b-instruct-turbo but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:15,370 WARNING    group clinical mentioned in run spec aci_bench:model=openai_gpt-4.1-2025-04-14,model_deployment=openai_gpt-4.1-2025-04-14 but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:15,370 WARNING    group clinical mentioned in run spec aci_bench:model=openai_gpt-4.1-mini-2025-04-14,model_deployment=openai_gpt-4.1-mini-2025-04-14 but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:15,371 WARNING    group clinical mentioned in run spec aci_bench:model=openai_gpt-4.1-nano-2025-04-14,model_deployment=openai_gpt-4.1-nano-2025-04-14 but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:15,371 WARNING    group clinical mentioned in run spec aci_bench:num_output_tokens=4000,model=deepseek-ai_deepseek-r1-0528,model_deployment=together_deepseek-r1-0528 but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:15,443 INFO       Writing 775 characters to benchmark_output/runs/my-medhelm-suite/groups/latex/clinical_note_generation_accuracy.tex
2025-08-15 00:34:15,446 INFO       Writing 13720 characters to benchmark_output/runs/my-medhelm-suite/groups/json/clinical_note_generation_accuracy.json
2025-08-15 00:34:15,447 INFO       Writing 798 characters to benchmark_output/runs/my-medhelm-suite/groups/latex/clinical_note_generation_efficiency.tex
2025-08-15 00:34:15,450 INFO       Writing 14171 characters to benchmark_output/runs/my-medhelm-suite/groups/json/clinical_note_generation_efficiency.json
2025-08-15 00:34:15,451 INFO       Writing 1086 characters to benchmark_output/runs/my-medhelm-suite/groups/latex/clinical_note_generation_general_information.tex
2025-08-15 00:34:15,461 INFO       Writing 54832 characters to benchmark_output/runs/my-medhelm-suite/groups/json/clinical_note_generation_general_information.json
2025-08-15 00:34:15,475 INFO       Writing 87873 characters to benchmark_output/runs/my-medhelm-suite/groups/clinical_note_generation.json
2025-08-15 00:34:15,477 WARNING    group clinical mentioned in run spec aci_bench:model=anthropic_claude-3-7-sonnet-20250219,model_deployment=anthropic_claude-3-7-sonnet-20250219 but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:15,477 WARNING    group clinical mentioned in run spec aci_bench:model=meta_llama-3.1-8b-instruct,model_deployment=huggingface_llama-3.1-8b-instruct but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:15,477 WARNING    group clinical mentioned in run spec aci_bench:model=meta_llama-3.2-1b-instruct,model_deployment=huggingface_llama-3.2-1b-instruct but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:15,477 WARNING    group clinical mentioned in run spec aci_bench:model=meta_llama-3.2-3b-instruct,model_deployment=huggingface_llama-3.2-3b-instruct but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:15,477 WARNING    group clinical mentioned in run spec aci_bench:model=meta_llama-3.3-70b-instruct-turbo,model_deployment=together_llama-3.3-70b-instruct-turbo but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:15,477 WARNING    group clinical mentioned in run spec aci_bench:model=openai_gpt-4.1-2025-04-14,model_deployment=openai_gpt-4.1-2025-04-14 but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:15,478 WARNING    group clinical mentioned in run spec aci_bench:model=openai_gpt-4.1-mini-2025-04-14,model_deployment=openai_gpt-4.1-mini-2025-04-14 but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:15,478 WARNING    group clinical mentioned in run spec aci_bench:model=openai_gpt-4.1-nano-2025-04-14,model_deployment=openai_gpt-4.1-nano-2025-04-14 but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:15,478 WARNING    group clinical mentioned in run spec aci_bench:num_output_tokens=4000,model=deepseek-ai_deepseek-r1-0528,model_deployment=together_deepseek-r1-0528 but undefined in schema_medhelm.yaml, skipping
2025-08-15 00:34:15,495 INFO       Writing 1387 characters to benchmark_output/runs/my-medhelm-suite/groups/latex/aci_bench_aci_bench_.tex
2025-08-15 00:34:15,498 INFO       Writing 19838 characters to benchmark_output/runs/my-medhelm-suite/groups/json/aci_bench_aci_bench_.json
2025-08-15 00:34:15,502 INFO       Writing 20980 characters to benchmark_output/runs/my-medhelm-suite/groups/aci_bench.json
2025-08-15 00:34:15,503 INFO       Summarizer.write_cost_report {
2025-08-15 00:34:15,503 INFO         Writing 2 characters to benchmark_output/runs/my-medhelm-suite/costs.json
2025-08-15 00:34:15,504 INFO       } [0.0s]
2025-08-15 00:34:15,504 INFO       Symlinking benchmark_output/runs/my-medhelm-suite to latest.
2025-08-15 00:34:15,505 INFO       Done.
2025-08-15 00:34:15,505 INFO     } [6.232s]
===== Benchmark Results =====
Model                             Jury Score            Observed inference time (s)    # eval    # train    truncated    # prompt tokens       # output tokens
Claude 3.7 Sonnet (20250219)      4.547222222222223     16.05382503668467              120.0                             1674.0583333333334    455.95
GPT-4.1 (2025-04-14)              4.477777777777777     13.234592833121617             120.0                             1573.6416666666667    511.8333333333333
DeepSeek-R1-0528                  4.419444444444446     18.903887156645457             120.0                             1613.1666666666667 
GPT-4.1-mini (2025-04-14)         4.366666666666666     8.03999240597089               120.0                             1573.6416666666667    435.7916666666667
GPT-4.1-nano (2025-04-14)         4.099999999999998     5.970380202929179              120.0                             1573.6416666666667    426.6666666666667
Llama 3.3 Instruct Turbo (70B)    4.050000000000001     29.972085070610046             120.0                             1629.5833333333333    429.7416666666667
Llama 3.1 Instruct (8B)           3.719444444444443     75.93968614141146              120.0                             1629.5833333333333    429.0833333333333
Llama 3.2 Instruct (3B)           3.244444444444444     59.51362446546555              120.0                             1629.5833333333333    391.3833333333333
Llama 3.2 Instruct (1.23B)        1.9000000000000004    19.747730922698974             10.0                              1447.3                221.7
