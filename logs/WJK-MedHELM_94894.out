2025-08-13 20:23:32,442 INFO     helm_run {
2025-08-13 20:23:33,466 INFO       Reading tokenizer configs from /data/wjkim9653/anaconda3/envs/HELM/lib/python3.10/site-packages/helm/config/tokenizer_configs.yaml...
2025-08-13 20:23:33,624 INFO       Reading model deployments from /data/wjkim9653/anaconda3/envs/HELM/lib/python3.10/site-packages/helm/config/model_deployments.yaml...
2025-08-13 20:23:34,289 INFO       Reading tokenizer configs from prod_env/tokenizer_configs.yaml...
2025-08-13 20:23:34,294 INFO       Reading model deployments from prod_env/model_deployments.yaml...
2025-08-13 20:23:34,401 INFO       Read 10 run entries from run_entries_medhelm_public.conf
2025-08-13 20:23:37,001 INFO       10 entries produced 1 run specs
2025-08-13 20:23:37,002 INFO       run_specs {
2025-08-13 20:23:37,002 INFO         RunSpec(name='aci_bench:model=meta_llama-3.2-3b-instruct,model_deployment=huggingface_llama-3.2-3b-instruct', scenario_spec=ScenarioSpec(class_name='helm.benchmark.scenarios.aci_bench_scenario.ACIBenchScenario', args={}), adapter_spec=AdapterSpec(method='generation', global_prefix='', global_suffix='', instructions='Summarize the conversation to generate a clinical note with four sections:\n1. HISTORY OF PRESENT ILLNESS\n2. PHYSICAL EXAM\n3. RESULTS\n4. ASSESSMENT AND PLAN\n\nThe conversation is:\n', input_prefix='Conversation: ', input_suffix='\n', reference_prefix='A. ', reference_suffix='\n', chain_of_thought_prefix='', chain_of_thought_suffix='\n', output_prefix='Clinical Note: ', output_suffix='\n', instance_prefix='\n', substitutions=[], max_train_instances=0, max_eval_instances=10, num_outputs=1, num_train_trials=1, num_trials=1, sample_train=True, model_deployment='huggingface/llama-3.2-3b-instruct', model='meta/llama-3.2-3b-instruct', temperature=0.0, max_tokens=768, stop_sequences=[], random=None, multi_label=False, image_generation_parameters=None, reeval_parameters=None, eval_splits=None), metric_specs=[MetricSpec(class_name='helm.benchmark.metrics.summarization_metrics.SummarizationMetric', args={'task': 'aci_bench', 'device': 'cuda', 'bertscore_model': 'distilbert-base-uncased', 'rescale_with_baseline': False}), MetricSpec(class_name='helm.benchmark.metrics.basic_metrics.BasicGenerationMetric', args={'names': []}), MetricSpec(class_name='helm.benchmark.metrics.basic_metrics.BasicReferenceMetric', args={}), MetricSpec(class_name='helm.benchmark.metrics.basic_metrics.InstancesPerSplitMetric', args={}), MetricSpec(class_name='helm.benchmark.metrics.aci_bench_metrics.ACIBenchMetric', args={})], data_augmenter_spec=DataAugmenterSpec(perturbation_specs=[], should_augment_train_instances=False, should_include_original_train=False, should_skip_unchanged_train=False, should_augment_eval_instances=False, should_include_original_eval=False, should_skip_unchanged_eval=False, seeds_per_instance=1), groups=['clinical', 'aci_bench'], annotators=[AnnotatorSpec(class_name='helm.benchmark.annotation.aci_bench_annotator.ACIBenchAnnotator', args={})])
2025-08-13 20:23:37,002 INFO       } [0.0s]
2025-08-13 20:23:37,002 INFO       Running in local mode with base path: prod_env
Looking in path: prod_env
2025-08-13 20:23:37,028 INFO       AutoTokenizer: cache_backend_config = BlackHoleCacheBackendConfig()
2025-08-13 20:23:37,028 INFO       AutoClient: file_storage_path = prod_env/cache
2025-08-13 20:23:37,028 INFO       AutoClient: cache_backend_config = BlackHoleCacheBackendConfig()
2025-08-13 20:23:37,028 INFO       AutoTokenizer: cache_backend_config = BlackHoleCacheBackendConfig()
Looking in path: prod_env
2025-08-13 20:23:37,051 INFO       AnnotatorFactory: file_storage_path = prod_env/cache
2025-08-13 20:23:37,052 INFO       AnnotatorFactory: cache_backend_config = BlackHoleCacheBackendConfig()
2025-08-13 20:23:37,054 INFO       Running aci_bench:model=meta_llama-3.2-3b-instruct,model_deployment=huggingface_llama-3.2-3b-instruct {
2025-08-13 20:23:37,057 INFO         scenario.get_instances {
2025-08-13 20:23:37,057 INFO           ensure_file_downloaded {
2025-08-13 20:23:37,058 INFO             Not downloading https://raw.githubusercontent.com/wyim/aci-bench/e75b383172195414a7a68843ec4876e83e5409f7/data/challenge_data_json/train_full.json because benchmark_output/scenarios/aci_bench/aci_bench_train.json already exists
2025-08-13 20:23:37,059 INFO           } [0.002s]
2025-08-13 20:23:37,064 INFO           ensure_file_downloaded {
2025-08-13 20:23:37,066 INFO             Not downloading https://raw.githubusercontent.com/wyim/aci-bench/e75b383172195414a7a68843ec4876e83e5409f7/data/challenge_data_json/clinicalnlp_taskB_test1_full.json because benchmark_output/scenarios/aci_bench/aci_bench_test_1.json already exists
2025-08-13 20:23:37,067 INFO           } [0.002s]
2025-08-13 20:23:37,070 INFO           ensure_file_downloaded {
2025-08-13 20:23:37,071 INFO             Not downloading https://raw.githubusercontent.com/wyim/aci-bench/e75b383172195414a7a68843ec4876e83e5409f7/data/challenge_data_json/clef_taskC_test3_full.json because benchmark_output/scenarios/aci_bench/aci_bench_test_2.json already exists
2025-08-13 20:23:37,071 INFO           } [0.001s]
2025-08-13 20:23:37,074 INFO           ensure_file_downloaded {
2025-08-13 20:23:37,076 INFO             Not downloading https://raw.githubusercontent.com/wyim/aci-bench/e75b383172195414a7a68843ec4876e83e5409f7/data/challenge_data_json/clinicalnlp_taskC_test2_full.json because benchmark_output/scenarios/aci_bench/aci_bench_test_3.json already exists
2025-08-13 20:23:37,076 INFO           } [0.001s]
2025-08-13 20:23:37,079 INFO         } [0.022s]
2025-08-13 20:23:37,082 INFO         187 instances, 67 train instances, 10/120 eval instances
2025-08-13 20:23:37,082 INFO         DataPreprocessor.preprocess {
2025-08-13 20:23:37,082 INFO         } [0.0s]
2025-08-13 20:23:37,084 INFO         GenerationAdapter.adapt {
2025-08-13 20:23:37,085 INFO           77 instances, choosing 0/67 train instances, 10 eval instances
2025-08-13 20:23:37,085 INFO           Adapting with train_trial_index=0 {
2025-08-13 20:23:37,085 INFO             Sampled 0 examples for trial #0.
2025-08-13 20:23:37,085 INFO             Parallelizing computation on 10 items over 4 threads {
2025-08-13 20:23:39,584 INFO               Created cache with config: BlackHoleCacheConfig()
2025-08-13 20:23:39,584 INFO               Loading meta-llama/Llama-3.2-3B-Instruct (kwargs={}) for HELM tokenizer meta/llama-3.2-3b-instruct with Hugging Face Transformers {
2025-08-13 20:23:39,584 INFO                 Created cache with config: BlackHoleCacheConfig()
2025-08-13 20:23:39,585 INFO                 Created cache with config: BlackHoleCacheConfig()
2025-08-13 20:23:39,585 INFO                 Created cache with config: BlackHoleCacheConfig()
2025-08-13 20:23:40,190 INFO               } [0.605s]
2025-08-13 20:23:40,448 INFO             } [3.362s]
2025-08-13 20:23:40,448 INFO             Sample prompts {
2025-08-13 20:23:40,448 INFO               reference index = None, request_mode = None {
2025-08-13 20:23:40,448 INFO                 Summarize the conversation to generate a clinical note with four sections:
2025-08-13 20:23:40,448 INFO                 1. HISTORY OF PRESENT ILLNESS
2025-08-13 20:23:40,448 INFO                 2. PHYSICAL EXAM
2025-08-13 20:23:40,448 INFO                 3. RESULTS
2025-08-13 20:23:40,448 INFO                 4. ASSESSMENT AND PLAN
2025-08-13 20:23:40,448 INFO                 
2025-08-13 20:23:40,448 INFO                 The conversation is:
2025-08-13 20:23:40,448 INFO                 
2025-08-13 20:23:40,448 INFO                 Conversation: Doctor-patient dialogue:
2025-08-13 20:23:40,449 INFO                 
2025-08-13 20:23:40,449 INFO                 [doctor] hi , alexander . how are you ?
2025-08-13 20:23:40,449 INFO                 [patient] i'm doing really well . thank you .
2025-08-13 20:23:40,449 INFO                 [doctor] so , i know the nurse told you a little bit about dax . i'd like to tell dax about you . okay ?
2025-08-13 20:23:40,449 INFO                 [patient] sure .
2025-08-13 20:23:40,449 INFO                 [doctor] so , alexander is a 62-year-old male , with a past medical history significant for reflux , who presents for follow-up of his chronic problems .
2025-08-13 20:23:40,449 INFO                 [doctor] so , alexander , what's being going on ?
2025-08-13 20:23:40,449 INFO                 [patient] well , i am so thankful you put me on that medicine for my , my reflux .
2025-08-13 20:23:40,449 INFO                 [doctor] the protonix ?
2025-08-13 20:23:40,449 INFO                 [patient] the protonix . that , i had , w- made an amazing change in my life .
2025-08-13 20:23:40,449 INFO                 [doctor] yeah .
2025-08-13 20:23:40,449 INFO                 [patient] i'm really comfortable now . i eat whatever i want , and i feel so much better .
2025-08-13 20:23:40,449 INFO                 [doctor] okay , great . i'm glad to hear that . i know you were having a lot of discomfort there before , so that's good . okay . and how are you doing , kind of , managing your diet ? i know , you know , you have to do some lifestyle modifications , like cutting back on caffeine and spicy foods and alcohol . how are you doing with that ?
2025-08-13 20:23:40,449 INFO                 [patient] i'm doing really well . i moved over from caffeine , over to green tea .
2025-08-13 20:23:40,449 INFO                 [doctor] okay .
2025-08-13 20:23:40,449 INFO                 [patient] and it , it is so , m- it does n't cause as much problem as it did with , when i was drinking so many energy drinks a day .
2025-08-13 20:23:40,449 INFO                 [doctor] all right . good . i'm glad to hear that . great . all right .
2025-08-13 20:23:40,449 INFO                 [patient] uh , i think getting that , rid of that reflux , really helped my attitude improve .
2025-08-13 20:23:40,449 INFO                 [doctor] okay .
2025-08-13 20:23:40,449 INFO                 [patient] uh , my job's going great . everything's phenomenal right now .
2025-08-13 20:23:40,449 INFO                 [doctor] okay .
2025-08-13 20:23:40,449 INFO                 [doctor] okay . and you have a , a good support system at home ? i know you have a big-
2025-08-13 20:23:40,449 INFO                 [patient] yeah .
2025-08-13 20:23:40,449 INFO                 [doctor] . family .
2025-08-13 20:23:40,449 INFO                 [patient] yes . yes . all my kids-
2025-08-13 20:23:40,449 INFO                 [doctor] okay .
2025-08-13 20:23:40,450 INFO                 [patient] . call and check on me every day .
2025-08-13 20:23:40,450 INFO                 [doctor] okay . great . i'm glad to hear that . now , i know you did a review of systems sheet when you checked in .
2025-08-13 20:23:40,450 INFO                 [patient] yes .
2025-08-13 20:23:40,450 INFO                 [doctor] i , are you having any symptoms ? any chest pain , shortness of breath , belly pain , of , nausea or vomiting ? anything like that ?
2025-08-13 20:23:40,450 INFO                 [patient] no . no symptoms at all .
2025-08-13 20:23:40,450 INFO                 [doctor] okay , great . um , well , let me go ahead . i wan na do a quick physical exam .
2025-08-13 20:23:40,450 INFO                 [doctor] hey , dragon . show me the vital signs .
2025-08-13 20:23:40,450 INFO                 [doctor] so , your vital signs here in the office look really good . so , you're doing a great job managing your , your blood pressure . your heart rate's nice and low . i'm gon na go ahead and take a listen to your heart and lungs .
2025-08-13 20:23:40,450 INFO                 [patient] okay .
2025-08-13 20:23:40,450 INFO                 [doctor] and i'll let you know what i find . okay ?
2025-08-13 20:23:40,450 INFO                 [patient] okay .
2025-08-13 20:23:40,450 INFO                 [doctor] okay . good . all right . so , on physical examination , i , i do n't hear any carotid bruits in your neck , which is really good . you know , your heart exam , i do hear a slight 2/6 systolic ejection murmur , which i've heard in the past , so that's stable . uh , your lungs are nice and clear , and you do have , you know , 1+ pitting edema bilaterally in your lower extremities .
2025-08-13 20:23:40,450 INFO                 [patient] okay .
2025-08-13 20:23:40,450 INFO                 [doctor] so , what does that mean ? you know , i , i think , you know , you're doing a ... it sounds like a doing a good job watching your diet . you could ... you just are retaining a little bit of fluid , maybe just from standing all day .
2025-08-13 20:23:40,450 INFO                 [patient] okay .
2025-08-13 20:23:40,450 INFO                 [doctor] okay ? let's take a look at some of your results . okay ?
2025-08-13 20:23:40,450 INFO                 [patient] okay .
2025-08-13 20:23:40,450 INFO                 [doctor] hey , dragon . show me the endoscope results .
2025-08-13 20:23:40,450 INFO                 [doctor] so , this was the endoscopy that you had last year when you were having all that pain . it just showed that you had had some mild gastritis . so , it's good to hear that that , you know , protonix is helping you a lot . okay ?
2025-08-13 20:23:40,450 INFO                 [patient] okay .
2025-08-13 20:23:40,450 INFO                 [patient] i'll do a little more exercise too .
2025-08-13 20:23:40,450 INFO                 [doctor] that sounds great . all right . so , let's talk just a little bit about , you know , my assessment and my plan for you .
2025-08-13 20:23:40,450 INFO                 [doctor] for your reflux , i want you to continue on the protonix 40 mg a day , and continue with those lifestyle modifications with the dietary stuff-
2025-08-13 20:23:40,450 INFO                 [patient] okay .
2025-08-13 20:23:40,450 INFO                 [doctor] . okay ? do you have any questions ?
2025-08-13 20:23:40,450 INFO                 [patient] no questions .
2025-08-13 20:23:40,451 INFO                 [doctor] okay . all right . well , the nurse is gon na come in soon , and she's gon na check you , get you checked out . okay ?
2025-08-13 20:23:40,451 INFO                 [patient] okay . thank you .
2025-08-13 20:23:40,451 INFO                 [doctor] hey , dragon . finalize the note .
2025-08-13 20:23:40,451 INFO                 Clinical Note:
2025-08-13 20:23:40,451 INFO               } [0.002s]
2025-08-13 20:23:40,451 INFO             } [0.002s]
2025-08-13 20:23:40,451 INFO           } [3.366s]
2025-08-13 20:23:40,451 INFO           10 requests
2025-08-13 20:23:40,451 INFO         } [3.366s]
2025-08-13 20:23:40,451 INFO         Executor.execute {
2025-08-13 20:23:40,451 INFO           Parallelizing computation on 10 items over 4 threads {
2025-08-13 20:23:40,470 INFO             Created cache with config: BlackHoleCacheConfig()
2025-08-13 20:23:40,470 INFO             Created cache with config: BlackHoleCacheConfig()
2025-08-13 20:23:40,470 WARNING          Automatically set `apply_chat_template` to True based on whether the tokenizer has a chat template. If this is incorrect, please explicitly set `apply_chat_template`.
2025-08-13 20:23:40,470 INFO             Created cache with config: BlackHoleCacheConfig()
2025-08-13 20:23:40,475 INFO             Created cache with config: BlackHoleCacheConfig()
2025-08-13 20:23:40,475 INFO             Created cache with config: BlackHoleCacheConfig()
2025-08-13 20:23:40,501 INFO             Loading meta-llama/Llama-3.2-3B-Instruct (kwargs={'torch_dtype': 'float16'}) for HELM model meta/llama-3.2-3b-instruct with Hugging Face Transformers {
2025-08-13 20:23:40,501 INFO               Hugging Face device set to "cuda:0" because CUDA is available.
2025-08-13 20:23:40,502 INFO               Loading Hugging Face model meta-llama/Llama-3.2-3B-Instruct {
2025-08-13 20:23:40,502 WARNING              Automatically set `apply_chat_template` to True based on whether the tokenizer has a chat template. If this is incorrect, please explicitly set `apply_chat_template`.
2025-08-13 20:23:40,502 WARNING              Automatically set `apply_chat_template` to True based on whether the tokenizer has a chat template. If this is incorrect, please explicitly set `apply_chat_template`.
2025-08-13 20:23:40,502 WARNING              Automatically set `apply_chat_template` to True based on whether the tokenizer has a chat template. If this is incorrect, please explicitly set `apply_chat_template`.
2025-08-13 20:23:46,878 INFO               } [6.375s]
2025-08-13 20:23:46,878 INFO             } [6.376s]
2025-08-13 20:24:34,261 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-13 20:24:37,844 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-13 20:24:45,224 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-13 20:24:53,565 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-13 20:25:37,076 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-13 20:25:37,738 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-13 20:25:42,257 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-13 20:25:43,235 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-13 20:26:09,106 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-13 20:26:09,172 WARNING          truncate_sequence needs to strip "<|eot_id|>"
2025-08-13 20:26:09,173 INFO           } [2m28.722s]
2025-08-13 20:26:09,174 INFO           Processed 10 requests
2025-08-13 20:26:09,174 INFO         } [2m28.722s]
2025-08-13 20:26:09,174 INFO         AnnotationExecutor.execute {
2025-08-13 20:26:09,180 INFO           AutoTokenizer: cache_backend_config = BlackHoleCacheBackendConfig()
2025-08-13 20:26:09,180 INFO           AutoClient: file_storage_path = prod_env/cache
2025-08-13 20:26:09,180 INFO           AutoClient: cache_backend_config = BlackHoleCacheBackendConfig()
2025-08-13 20:26:09,181 INFO           Parallelizing computation on 10 items over 4 threads {
2025-08-13 20:26:10,357 INFO             Created cache with config: BlackHoleCacheConfig()
2025-08-13 20:26:10,357 INFO             Using host_organization api key defined in credentials.conf: openaiApiKey
2025-08-13 20:26:10,357 INFO             Created cache with config: BlackHoleCacheConfig()
2025-08-13 20:26:10,359 INFO             Created cache with config: BlackHoleCacheConfig()
2025-08-13 20:26:10,359 INFO             Using host_organization api key defined in credentials.conf: openaiApiKey
2025-08-13 20:26:10,359 INFO             Created cache with config: BlackHoleCacheConfig()
2025-08-13 20:26:10,360 INFO             Created cache with config: BlackHoleCacheConfig()
2025-08-13 20:26:10,360 INFO             Created cache with config: BlackHoleCacheConfig()
2025-08-13 20:26:10,361 INFO             Using host_organization api key defined in credentials.conf: openaiApiKey
2025-08-13 20:26:10,361 INFO             Using host_organization api key defined in credentials.conf: openaiApiKey
2025-08-13 20:26:10,361 INFO             Created cache with config: BlackHoleCacheConfig()
2025-08-13 20:26:10,361 INFO             Created cache with config: BlackHoleCacheConfig()
2025-08-13 20:26:42,775 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-13 20:26:50,798 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-13 20:27:05,765 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-13 20:27:15,718 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-13 20:27:31,614 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-13 20:27:38,120 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-13 20:27:41,034 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-13 20:27:56,502 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-13 20:28:12,638 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-13 20:28:13,317 INFO             Failed model annotations: {'gpt-5': 0}
2025-08-13 20:28:13,318 INFO           } [2m4.137s]
2025-08-13 20:28:13,318 INFO           Annotated 10 requests
2025-08-13 20:28:13,318 INFO         } [2m4.144s]
2025-08-13 20:28:17,407 INFO         5 metrics {
2025-08-13 20:28:17,407 INFO           <helm.benchmark.metrics.summarization_metrics.SummarizationMetric object at 0x7febad0ec7f0> {
2025-08-13 20:28:17,407 INFO             Setting parallelism from 4 to 1, since evaluating faithfulness with parallelism > 1 errors.
2025-08-13 20:28:17,407 INFO             Parallelizing computation on 10 items over 1 threads {
2025-08-13 20:28:17,407 INFO               ensure_file_downloaded {
2025-08-13 20:28:17,409 INFO                 Not downloading https://storage.googleapis.com/crfm-helm-public/source_datasets/metrics/summarization_metrics/qafacteval.pk because benchmark_output/runs/my-medhelm-suite/eval_cache/qafacteval.pk already exists
2025-08-13 20:28:17,409 INFO               } [0.001s]
2025-08-13 20:29:15,349 INFO             } [57.942s]
2025-08-13 20:29:15,361 INFO           } [57.953s]
2025-08-13 20:29:15,361 INFO           BasicMetric() {
2025-08-13 20:29:15,361 INFO             Parallelizing computation on 10 items over 4 threads {
2025-08-13 20:29:15,435 INFO             } [0.073s]
2025-08-13 20:29:15,450 INFO           } [0.089s]
2025-08-13 20:29:15,450 INFO           BasicReferenceMetric {
2025-08-13 20:29:15,450 INFO             Parallelizing computation on 10 items over 4 threads {
2025-08-13 20:29:15,452 INFO             } [0.001s]
2025-08-13 20:29:15,452 INFO           } [0.001s]
2025-08-13 20:29:15,452 INFO           <helm.benchmark.metrics.basic_metrics.InstancesPerSplitMetric object at 0x7feb695bafb0> {
2025-08-13 20:29:15,452 INFO           } [0.0s]
2025-08-13 20:29:15,452 INFO           <helm.benchmark.metrics.aci_bench_metrics.ACIBenchMetric object at 0x7feb695bb040> {
2025-08-13 20:29:15,452 INFO             Parallelizing computation on 10 items over 4 threads {
2025-08-13 20:29:15,454 INFO             } [0.001s]
2025-08-13 20:29:15,455 INFO           } [0.002s]
2025-08-13 20:29:15,455 INFO         } [58.048s]
2025-08-13 20:29:15,455 INFO         Generated 90 stats.
2025-08-13 20:29:15,456 INFO         Writing 2529 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=meta_llama-3.2-3b-instruct,model_deployment=huggingface_llama-3.2-3b-instruct/run_spec.json
2025-08-13 20:29:15,458 INFO         Writing 567 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=meta_llama-3.2-3b-instruct,model_deployment=huggingface_llama-3.2-3b-instruct/scenario.json
2025-08-13 20:29:15,522 INFO         Writing 656586 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=meta_llama-3.2-3b-instruct,model_deployment=huggingface_llama-3.2-3b-instruct/scenario_state.json
2025-08-13 20:29:15,533 INFO         Writing 32483 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=meta_llama-3.2-3b-instruct,model_deployment=huggingface_llama-3.2-3b-instruct/stats.json
2025-08-13 20:29:15,553 INFO         Writing 95095 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=meta_llama-3.2-3b-instruct,model_deployment=huggingface_llama-3.2-3b-instruct/per_instance_stats.json
2025-08-13 20:29:15,554 INFO         CacheStats.print_status {
2025-08-13 20:29:15,554 INFO           disabled_cache: 70 queries, 70 computes
2025-08-13 20:29:15,554 INFO         } [0.0s]
2025-08-13 20:29:15,554 INFO       } [5m38.5s]
2025-08-13 20:29:15,555 INFO       Done.
2025-08-13 20:29:15,555 INFO     } [5m43.112s]
2025-08-13 20:29:23,273 INFO     summarize: summarize {
2025-08-13 20:29:24,391 INFO       Reading tokenizer configs from /data/wjkim9653/anaconda3/envs/HELM/lib/python3.10/site-packages/helm/config/tokenizer_configs.yaml...
2025-08-13 20:29:24,553 INFO       Reading model deployments from /data/wjkim9653/anaconda3/envs/HELM/lib/python3.10/site-packages/helm/config/model_deployments.yaml...
2025-08-13 20:29:25,354 INFO       Reading tokenizer configs from prod_env/tokenizer_configs.yaml...
2025-08-13 20:29:25,360 INFO       Reading model deployments from prod_env/model_deployments.yaml...
2025-08-13 20:29:25,379 INFO       Reading schema file schema_medhelm.yaml...
2025-08-13 20:29:25,611 WARNING    aci_bench:model=gemini_gemini-2.0-flash,model_deployment=gemini_gemini-2.0-flash doesn't have run_spec.json or stats.json, skipping
2025-08-13 20:29:25,639 WARNING    benchmark_output doesn't have run_spec.json or stats.json, skipping
2025-08-13 20:29:25,639 INFO       Summarizer.check_metrics_defined {
2025-08-13 20:29:25,639 INFO       } [0.0s]
2025-08-13 20:29:25,639 INFO       Parallelizing computation on 9 items over 8 threads {
2025-08-13 20:29:25,640 INFO         write_run_display_json {
2025-08-13 20:29:25,640 INFO           write_run_display_json {
2025-08-13 20:29:25,641 INFO             write_run_display_json {
2025-08-13 20:29:25,641 INFO             write_run_display_json {
2025-08-13 20:29:25,642 INFO                 write_run_display_json {
2025-08-13 20:29:25,642 INFO                   write_run_display_json {
2025-08-13 20:29:25,643 INFO                     write_run_display_json {
2025-08-13 20:29:25,649 INFO                       write_run_display_json {
2025-08-13 20:29:25,832 INFO                         Writing 83790 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=meta_llama-3.2-1b-instruct,model_deployment=huggingface_llama-3.2-1b-instruct/instances.json
2025-08-13 20:29:25,838 INFO                         Writing 83790 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=anthropic_claude-3-7-sonnet-20250219,model_deployment=anthropic_claude-3-7-sonnet-20250219/instances.json
2025-08-13 20:29:25,842 INFO                         Writing 83790 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=meta_llama-3.2-3b-instruct,model_deployment=huggingface_llama-3.2-3b-instruct/instances.json
2025-08-13 20:29:25,842 INFO                         Writing 83790 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=meta_llama-3.3-70b-instruct-turbo,model_deployment=together_llama-3.3-70b-instruct-turbo/instances.json
2025-08-13 20:29:25,872 INFO                         Writing 155492 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=meta_llama-3.2-3b-instruct,model_deployment=huggingface_llama-3.2-3b-instruct/display_predictions.json
2025-08-13 20:29:25,879 INFO                         Writing 139464 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=meta_llama-3.2-1b-instruct,model_deployment=huggingface_llama-3.2-1b-instruct/display_predictions.json
2025-08-13 20:29:25,893 INFO                         Writing 158125 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=anthropic_claude-3-7-sonnet-20250219,model_deployment=anthropic_claude-3-7-sonnet-20250219/display_predictions.json
2025-08-13 20:29:25,913 INFO                         Writing 83790 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=openai_gpt-4.1-2025-04-14,model_deployment=openai_gpt-4.1-2025-04-14/instances.json
2025-08-13 20:29:25,919 INFO                         Writing 83790 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=openai_gpt-4.1-mini-2025-04-14,model_deployment=openai_gpt-4.1-mini-2025-04-14/instances.json
2025-08-13 20:29:25,921 INFO                         Writing 156771 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=meta_llama-3.3-70b-instruct-turbo,model_deployment=together_llama-3.3-70b-instruct-turbo/display_predictions.json
2025-08-13 20:29:25,923 INFO                         Writing 83790 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=meta_llama-3.1-8b-instruct,model_deployment=huggingface_llama-3.1-8b-instruct/instances.json
2025-08-13 20:29:25,930 INFO                         Writing 83790 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=openai_gpt-4.1-nano-2025-04-14,model_deployment=openai_gpt-4.1-nano-2025-04-14/instances.json
2025-08-13 20:29:25,932 INFO                         Writing 63533 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=meta_llama-3.2-3b-instruct,model_deployment=huggingface_llama-3.2-3b-instruct/display_requests.json
2025-08-13 20:29:25,934 INFO                         Writing 63533 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=meta_llama-3.2-1b-instruct,model_deployment=huggingface_llama-3.2-1b-instruct/display_requests.json
2025-08-13 20:29:25,935 INFO                         Writing 63663 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=anthropic_claude-3-7-sonnet-20250219,model_deployment=anthropic_claude-3-7-sonnet-20250219/display_requests.json
2025-08-13 20:29:25,937 INFO                         Writing 63643 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=meta_llama-3.3-70b-instruct-turbo,model_deployment=together_llama-3.3-70b-instruct-turbo/display_requests.json
2025-08-13 20:29:25,939 INFO                         Writing 164354 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=openai_gpt-4.1-2025-04-14,model_deployment=openai_gpt-4.1-2025-04-14/display_predictions.json
2025-08-13 20:29:25,940 INFO                       } [0.291s]
2025-08-13 20:29:25,942 INFO                       Writing 158200 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=meta_llama-3.1-8b-instruct,model_deployment=huggingface_llama-3.1-8b-instruct/display_predictions.json
2025-08-13 20:29:25,943 INFO                     } [0.299s]
2025-08-13 20:29:25,945 INFO                     Writing 159842 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=openai_gpt-4.1-mini-2025-04-14,model_deployment=openai_gpt-4.1-mini-2025-04-14/display_predictions.json
2025-08-13 20:29:25,946 INFO                   } [0.303s]
2025-08-13 20:29:25,948 INFO                   Writing 159308 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=openai_gpt-4.1-nano-2025-04-14,model_deployment=openai_gpt-4.1-nano-2025-04-14/display_predictions.json
2025-08-13 20:29:25,948 INFO                   write_run_display_json {
2025-08-13 20:29:25,949 INFO                   } [0.0s]
2025-08-13 20:29:25,955 INFO                   Writing 63543 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=openai_gpt-4.1-mini-2025-04-14,model_deployment=openai_gpt-4.1-mini-2025-04-14/display_requests.json
2025-08-13 20:29:25,956 INFO                   Writing 63543 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=openai_gpt-4.1-nano-2025-04-14,model_deployment=openai_gpt-4.1-nano-2025-04-14/display_requests.json
2025-08-13 20:29:25,956 INFO                   Writing 63533 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=meta_llama-3.1-8b-instruct,model_deployment=huggingface_llama-3.1-8b-instruct/display_requests.json
2025-08-13 20:29:25,957 INFO                   Writing 63443 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:model=openai_gpt-4.1-2025-04-14,model_deployment=openai_gpt-4.1-2025-04-14/display_requests.json
2025-08-13 20:29:25,970 INFO                 } [0.328s]
2025-08-13 20:29:25,976 INFO               } [0.334s]
2025-08-13 20:29:25,977 INFO             } [0.335s]
2025-08-13 20:29:25,977 INFO           } [0.336s]
2025-08-13 20:29:25,978 INFO           Writing 83790 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:num_output_tokens=4000,model=deepseek-ai_deepseek-r1-0528,model_deployment=together_deepseek-r1-0528/instances.json
2025-08-13 20:29:25,982 INFO           Writing 185190 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:num_output_tokens=4000,model=deepseek-ai_deepseek-r1-0528,model_deployment=together_deepseek-r1-0528/display_predictions.json
2025-08-13 20:29:25,985 INFO           Writing 63483 characters to benchmark_output/runs/my-medhelm-suite/aci_bench:num_output_tokens=4000,model=deepseek-ai_deepseek-r1-0528,model_deployment=together_deepseek-r1-0528/display_requests.json
2025-08-13 20:29:25,986 INFO         } [0.345s]
2025-08-13 20:29:25,987 INFO       } [0.347s]
2025-08-13 20:29:25,996 INFO       Writing 83175 characters to benchmark_output/runs/my-medhelm-suite/schema.json
2025-08-13 20:29:25,997 INFO       Summarizer.write_executive_summary {
2025-08-13 20:29:25,998 INFO         Writing 99 characters to benchmark_output/runs/my-medhelm-suite/summary.json
2025-08-13 20:29:25,998 INFO       } [0.001s]
2025-08-13 20:29:26,063 INFO       Writing 371686 characters to benchmark_output/runs/my-medhelm-suite/runs.json
2025-08-13 20:29:26,069 INFO       Writing 24339 characters to benchmark_output/runs/my-medhelm-suite/run_specs.json
2025-08-13 20:29:26,070 INFO       Writing 1107 characters to benchmark_output/runs/my-medhelm-suite/runs_to_run_suites.json
2025-08-13 20:29:26,071 WARNING    group clinical mentioned in run spec aci_bench:model=anthropic_claude-3-7-sonnet-20250219,model_deployment=anthropic_claude-3-7-sonnet-20250219 but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,071 WARNING    group clinical mentioned in run spec aci_bench:model=meta_llama-3.1-8b-instruct,model_deployment=huggingface_llama-3.1-8b-instruct but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,072 WARNING    group clinical mentioned in run spec aci_bench:model=meta_llama-3.2-1b-instruct,model_deployment=huggingface_llama-3.2-1b-instruct but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,072 WARNING    group clinical mentioned in run spec aci_bench:model=meta_llama-3.2-3b-instruct,model_deployment=huggingface_llama-3.2-3b-instruct but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,072 WARNING    group clinical mentioned in run spec aci_bench:model=meta_llama-3.3-70b-instruct-turbo,model_deployment=together_llama-3.3-70b-instruct-turbo but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,072 WARNING    group clinical mentioned in run spec aci_bench:model=openai_gpt-4.1-2025-04-14,model_deployment=openai_gpt-4.1-2025-04-14 but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,072 WARNING    group clinical mentioned in run spec aci_bench:model=openai_gpt-4.1-mini-2025-04-14,model_deployment=openai_gpt-4.1-mini-2025-04-14 but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,072 WARNING    group clinical mentioned in run spec aci_bench:model=openai_gpt-4.1-nano-2025-04-14,model_deployment=openai_gpt-4.1-nano-2025-04-14 but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,072 WARNING    group clinical mentioned in run spec aci_bench:num_output_tokens=4000,model=deepseek-ai_deepseek-r1-0528,model_deployment=together_deepseek-r1-0528 but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,073 WARNING    group clinical mentioned in run spec aci_bench:model=anthropic_claude-3-7-sonnet-20250219,model_deployment=anthropic_claude-3-7-sonnet-20250219 but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,073 WARNING    group clinical mentioned in run spec aci_bench:model=meta_llama-3.1-8b-instruct,model_deployment=huggingface_llama-3.1-8b-instruct but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,073 WARNING    group clinical mentioned in run spec aci_bench:model=meta_llama-3.2-1b-instruct,model_deployment=huggingface_llama-3.2-1b-instruct but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,073 WARNING    group clinical mentioned in run spec aci_bench:model=meta_llama-3.2-3b-instruct,model_deployment=huggingface_llama-3.2-3b-instruct but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,074 WARNING    group clinical mentioned in run spec aci_bench:model=meta_llama-3.3-70b-instruct-turbo,model_deployment=together_llama-3.3-70b-instruct-turbo but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,074 WARNING    group clinical mentioned in run spec aci_bench:model=openai_gpt-4.1-2025-04-14,model_deployment=openai_gpt-4.1-2025-04-14 but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,074 WARNING    group clinical mentioned in run spec aci_bench:model=openai_gpt-4.1-mini-2025-04-14,model_deployment=openai_gpt-4.1-mini-2025-04-14 but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,074 WARNING    group clinical mentioned in run spec aci_bench:model=openai_gpt-4.1-nano-2025-04-14,model_deployment=openai_gpt-4.1-nano-2025-04-14 but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,074 WARNING    group clinical mentioned in run spec aci_bench:num_output_tokens=4000,model=deepseek-ai_deepseek-r1-0528,model_deployment=together_deepseek-r1-0528 but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,075 WARNING    group clinical mentioned in run spec aci_bench:model=anthropic_claude-3-7-sonnet-20250219,model_deployment=anthropic_claude-3-7-sonnet-20250219 but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,075 WARNING    group clinical mentioned in run spec aci_bench:model=meta_llama-3.1-8b-instruct,model_deployment=huggingface_llama-3.1-8b-instruct but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,075 WARNING    group clinical mentioned in run spec aci_bench:model=meta_llama-3.2-1b-instruct,model_deployment=huggingface_llama-3.2-1b-instruct but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,076 WARNING    group clinical mentioned in run spec aci_bench:model=meta_llama-3.2-3b-instruct,model_deployment=huggingface_llama-3.2-3b-instruct but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,076 WARNING    group clinical mentioned in run spec aci_bench:model=meta_llama-3.3-70b-instruct-turbo,model_deployment=together_llama-3.3-70b-instruct-turbo but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,076 WARNING    group clinical mentioned in run spec aci_bench:model=openai_gpt-4.1-2025-04-14,model_deployment=openai_gpt-4.1-2025-04-14 but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,076 WARNING    group clinical mentioned in run spec aci_bench:model=openai_gpt-4.1-mini-2025-04-14,model_deployment=openai_gpt-4.1-mini-2025-04-14 but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,076 WARNING    group clinical mentioned in run spec aci_bench:model=openai_gpt-4.1-nano-2025-04-14,model_deployment=openai_gpt-4.1-nano-2025-04-14 but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,076 WARNING    group clinical mentioned in run spec aci_bench:num_output_tokens=4000,model=deepseek-ai_deepseek-r1-0528,model_deployment=together_deepseek-r1-0528 but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,087 INFO       Writing 41504 characters to benchmark_output/runs/my-medhelm-suite/groups.json
2025-08-13 20:29:26,089 INFO       Writing 24387 characters to benchmark_output/runs/my-medhelm-suite/groups_metadata.json
2025-08-13 20:29:26,091 WARNING    group clinical mentioned in run spec aci_bench:model=anthropic_claude-3-7-sonnet-20250219,model_deployment=anthropic_claude-3-7-sonnet-20250219 but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,091 WARNING    group clinical mentioned in run spec aci_bench:model=meta_llama-3.1-8b-instruct,model_deployment=huggingface_llama-3.1-8b-instruct but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,091 WARNING    group clinical mentioned in run spec aci_bench:model=meta_llama-3.2-1b-instruct,model_deployment=huggingface_llama-3.2-1b-instruct but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,091 WARNING    group clinical mentioned in run spec aci_bench:model=meta_llama-3.2-3b-instruct,model_deployment=huggingface_llama-3.2-3b-instruct but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,091 WARNING    group clinical mentioned in run spec aci_bench:model=meta_llama-3.3-70b-instruct-turbo,model_deployment=together_llama-3.3-70b-instruct-turbo but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,091 WARNING    group clinical mentioned in run spec aci_bench:model=openai_gpt-4.1-2025-04-14,model_deployment=openai_gpt-4.1-2025-04-14 but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,092 WARNING    group clinical mentioned in run spec aci_bench:model=openai_gpt-4.1-mini-2025-04-14,model_deployment=openai_gpt-4.1-mini-2025-04-14 but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,092 WARNING    group clinical mentioned in run spec aci_bench:model=openai_gpt-4.1-nano-2025-04-14,model_deployment=openai_gpt-4.1-nano-2025-04-14 but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,092 WARNING    group clinical mentioned in run spec aci_bench:num_output_tokens=4000,model=deepseek-ai_deepseek-r1-0528,model_deployment=together_deepseek-r1-0528 but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,480 INFO       Writing 721 characters to benchmark_output/runs/my-medhelm-suite/groups/latex/medhelm_scenarios_accuracy.tex
2025-08-13 20:29:26,492 INFO       Writing 58102 characters to benchmark_output/runs/my-medhelm-suite/groups/json/medhelm_scenarios_accuracy.json
2025-08-13 20:29:26,495 INFO       Writing 782 characters to benchmark_output/runs/my-medhelm-suite/groups/latex/medhelm_scenarios_efficiency.tex
2025-08-13 20:29:26,506 INFO       Writing 61048 characters to benchmark_output/runs/my-medhelm-suite/groups/json/medhelm_scenarios_efficiency.json
2025-08-13 20:29:26,509 INFO       Writing 895 characters to benchmark_output/runs/my-medhelm-suite/groups/latex/medhelm_scenarios_general_information.tex
2025-08-13 20:29:26,558 INFO       Writing 266638 characters to benchmark_output/runs/my-medhelm-suite/groups/json/medhelm_scenarios_general_information.json
2025-08-13 20:29:26,630 INFO       Writing 410592 characters to benchmark_output/runs/my-medhelm-suite/groups/medhelm_scenarios.json
2025-08-13 20:29:26,634 WARNING    group clinical mentioned in run spec aci_bench:model=anthropic_claude-3-7-sonnet-20250219,model_deployment=anthropic_claude-3-7-sonnet-20250219 but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,634 WARNING    group clinical mentioned in run spec aci_bench:model=meta_llama-3.1-8b-instruct,model_deployment=huggingface_llama-3.1-8b-instruct but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,634 WARNING    group clinical mentioned in run spec aci_bench:model=meta_llama-3.2-1b-instruct,model_deployment=huggingface_llama-3.2-1b-instruct but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,634 WARNING    group clinical mentioned in run spec aci_bench:model=meta_llama-3.2-3b-instruct,model_deployment=huggingface_llama-3.2-3b-instruct but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,635 WARNING    group clinical mentioned in run spec aci_bench:model=meta_llama-3.3-70b-instruct-turbo,model_deployment=together_llama-3.3-70b-instruct-turbo but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,635 WARNING    group clinical mentioned in run spec aci_bench:model=openai_gpt-4.1-2025-04-14,model_deployment=openai_gpt-4.1-2025-04-14 but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,635 WARNING    group clinical mentioned in run spec aci_bench:model=openai_gpt-4.1-mini-2025-04-14,model_deployment=openai_gpt-4.1-mini-2025-04-14 but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,635 WARNING    group clinical mentioned in run spec aci_bench:model=openai_gpt-4.1-nano-2025-04-14,model_deployment=openai_gpt-4.1-nano-2025-04-14 but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,635 WARNING    group clinical mentioned in run spec aci_bench:num_output_tokens=4000,model=deepseek-ai_deepseek-r1-0528,model_deployment=together_deepseek-r1-0528 but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,706 INFO       Writing 735 characters to benchmark_output/runs/my-medhelm-suite/groups/latex/clinical_note_generation_accuracy.tex
2025-08-13 20:29:26,710 INFO       Writing 13668 characters to benchmark_output/runs/my-medhelm-suite/groups/json/clinical_note_generation_accuracy.json
2025-08-13 20:29:26,712 INFO       Writing 796 characters to benchmark_output/runs/my-medhelm-suite/groups/latex/clinical_note_generation_efficiency.tex
2025-08-13 20:29:26,716 INFO       Writing 14169 characters to benchmark_output/runs/my-medhelm-suite/groups/json/clinical_note_generation_efficiency.json
2025-08-13 20:29:26,717 INFO       Writing 909 characters to benchmark_output/runs/my-medhelm-suite/groups/latex/clinical_note_generation_general_information.tex
2025-08-13 20:29:26,726 INFO       Writing 54507 characters to benchmark_output/runs/my-medhelm-suite/groups/json/clinical_note_generation_general_information.json
2025-08-13 20:29:26,741 INFO       Writing 87494 characters to benchmark_output/runs/my-medhelm-suite/groups/clinical_note_generation.json
2025-08-13 20:29:26,743 WARNING    group clinical mentioned in run spec aci_bench:model=anthropic_claude-3-7-sonnet-20250219,model_deployment=anthropic_claude-3-7-sonnet-20250219 but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,744 WARNING    group clinical mentioned in run spec aci_bench:model=meta_llama-3.1-8b-instruct,model_deployment=huggingface_llama-3.1-8b-instruct but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,744 WARNING    group clinical mentioned in run spec aci_bench:model=meta_llama-3.2-1b-instruct,model_deployment=huggingface_llama-3.2-1b-instruct but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,744 WARNING    group clinical mentioned in run spec aci_bench:model=meta_llama-3.2-3b-instruct,model_deployment=huggingface_llama-3.2-3b-instruct but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,744 WARNING    group clinical mentioned in run spec aci_bench:model=meta_llama-3.3-70b-instruct-turbo,model_deployment=together_llama-3.3-70b-instruct-turbo but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,744 WARNING    group clinical mentioned in run spec aci_bench:model=openai_gpt-4.1-2025-04-14,model_deployment=openai_gpt-4.1-2025-04-14 but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,744 WARNING    group clinical mentioned in run spec aci_bench:model=openai_gpt-4.1-mini-2025-04-14,model_deployment=openai_gpt-4.1-mini-2025-04-14 but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,744 WARNING    group clinical mentioned in run spec aci_bench:model=openai_gpt-4.1-nano-2025-04-14,model_deployment=openai_gpt-4.1-nano-2025-04-14 but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,744 WARNING    group clinical mentioned in run spec aci_bench:num_output_tokens=4000,model=deepseek-ai_deepseek-r1-0528,model_deployment=together_deepseek-r1-0528 but undefined in schema_medhelm.yaml, skipping
2025-08-13 20:29:26,762 INFO       Writing 1168 characters to benchmark_output/runs/my-medhelm-suite/groups/latex/aci_bench_aci_bench_.tex
2025-08-13 20:29:26,767 INFO       Writing 19459 characters to benchmark_output/runs/my-medhelm-suite/groups/json/aci_bench_aci_bench_.json
2025-08-13 20:29:26,771 INFO       Writing 20601 characters to benchmark_output/runs/my-medhelm-suite/groups/aci_bench.json
2025-08-13 20:29:26,773 INFO       Summarizer.write_cost_report {
2025-08-13 20:29:26,773 INFO         Writing 2 characters to benchmark_output/runs/my-medhelm-suite/costs.json
2025-08-13 20:29:26,774 INFO       } [0.001s]
2025-08-13 20:29:26,774 INFO       Symlinking benchmark_output/runs/my-medhelm-suite to latest.
2025-08-13 20:29:26,775 INFO       Done.
2025-08-13 20:29:26,775 INFO     } [3.501s]
===== Benchmark Results =====
Model                             Jury Score            Observed inference time (s)    # eval    # train    truncated    # prompt tokens    # output tokens
Claude 3.7 Sonnet (20250219)      4.7                   9.940697169303894              10.0                              1515.8             413.8
GPT-4.1 (2025-04-14)              4.533333333333333     9.810245203971864              10.0                              1399.9             480.4
DeepSeek-R1-0528                  4.433333333333334     19.03376421928406              10.0                              1433.1 
GPT-4.1-mini (2025-04-14)         4.4                   6.828373408317566              10.0                              1399.9             403.8
Llama 3.3 Instruct Turbo (70B)    4.166666666666667     64.59834017753602              10.0                              1447.3             400.8
GPT-4.1-nano (2025-04-14)         4.1                   8.015656733512879              10.0                              1399.9             387.5
Llama 3.1 Instruct (8B)           3.8666666666666663    67.02340290546417              10.0                              1447.3             404.1
Llama 3.2 Instruct (3B)           3.3333333333333335    51.62401144504547              10.0                              1447.3             362.4
Llama 3.2 Instruct (1.23B)        1.9000000000000004    19.747730922698974             10.0                              1447.3             221.7
