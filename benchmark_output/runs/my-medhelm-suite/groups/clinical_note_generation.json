[
  {
    "title": "Accuracy",
    "header": [
      {
        "value": "Model",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "Mean win rate",
        "description": "How many models this model outperforms on average (over columns).",
        "markdown": false,
        "lower_is_better": false,
        "metadata": {}
      },
      {
        "value": "DischargeMe - Jury Score",
        "description": "DischargeMe is a benchmark designed to evaluate clinical text generation. It pairs discharge summaries and radiology reports from MIMIC-IV with generation tasks such as writing discharge instructions or summarizing the brief hospital course. The benchmark assesses a model's ability to generate patient-facing documentation that is complete, empathetic, and clinically accurate [(Xu, 2024)](https://physionet.org/content/discharge-me/1.3/).\n\nDischargeMe Jury Score: Measures the average score assigned by an LLM-based jury evaluating task performance.",
        "markdown": false,
        "lower_is_better": false,
        "metadata": {
          "metric": "Jury Score",
          "run_group": "DischargeMe"
        }
      },
      {
        "value": "ACI-Bench - Jury Score",
        "description": "ACI-Bench is a benchmark of real-world patient-doctor conversations paired with structured clinical notes. The benchmark evaluates a model's ability to understand spoken medical dialogue and convert it into formal clinical documentation, covering sections such as history of present illness, physical exam findings, results, and assessment and plan [(Yim et al., 2024)](https://www.nature.com/articles/s41597-023-02487-3).\n\nACI-Bench Jury Score: Measures the average score assigned by an LLM-based jury evaluating task performance.",
        "markdown": false,
        "lower_is_better": false,
        "metadata": {
          "metric": "Jury Score",
          "run_group": "ACI-Bench"
        }
      },
      {
        "value": "MTSamples Procedures - Jury Score",
        "description": "MTSamples Procedures is a benchmark composed of transcribed operative notes, focused on documenting surgical procedures. Each example presents a brief patient case involving a surgical intervention, and the model is tasked with generating a coherent and clinically accurate procedural summary or treatment plan.\n\nMTSamples Procedures Jury Score: Measures the average score assigned by an LLM-based jury evaluating task performance.",
        "markdown": false,
        "lower_is_better": false,
        "metadata": {
          "metric": "Jury Score",
          "run_group": "MTSamples Procedures"
        }
      },
      {
        "value": "MIMIC-RRS - Jury Score",
        "description": "MIMIC-RRS is a benchmark constructed from radiology reports in the MIMIC-III database. It contains pairs of \u2018Findings\u2018 and \u2018Impression\u2018 sections, enabling evaluation of a model's ability to summarize diagnostic imaging observations into concise, clinically relevant conclusions [(Chen et al., 2023)](https://arxiv.org/abs/2211.08584).\n\nMIMIC-RRS Jury Score: Measures the average score assigned by an LLM-based jury evaluating task performance.",
        "markdown": false,
        "lower_is_better": false,
        "metadata": {
          "metric": "Jury Score",
          "run_group": "MIMIC-RRS"
        }
      },
      {
        "value": "MIMIC-BHC - Jury Score",
        "description": "MIMIC-BHC is a benchmark focused on summarization of discharge notes into Brief Hospital Course (BHC) sections. It consists of curated discharge notes from MIMIC-IV, each paired with its corresponding BHC summary. The benchmark evaluates a model's ability to condense detailed clinical information into accurate, concise summaries that reflect the patient's hospital stay [(Aali et al., 2024)](https://doi.org/10.1093/jamia/ocae312).\n\nMIMIC-BHC Jury Score: Measures the average score assigned by an LLM-based jury evaluating task performance.",
        "markdown": false,
        "lower_is_better": false,
        "metadata": {
          "metric": "Jury Score",
          "run_group": "MIMIC-BHC"
        }
      },
      {
        "value": "NoteExtract - Jury Score",
        "description": "NoteExtract is a benchmark that focuses on the structured extraction of information from free-form clinical text. It provides care plan notes authored by health workers and evaluates a model's ability to convert them into a predefined structured format, such as fields for Chief Complaint and History of Present Illness. The benchmark emphasizes faithful extraction without hallucination or inference.\n\nNoteExtract Jury Score: Measures the average score assigned by an LLM-based jury evaluating task performance.",
        "markdown": false,
        "lower_is_better": false,
        "metadata": {
          "metric": "Jury Score",
          "run_group": "NoteExtract"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "Llama 3.1 Instruct (8B)",
          "description": "",
          "markdown": false
        },
        {
          "value": 0.25,
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "value": 3.7999999999999994,
          "description": "min=3.8, mean=3.8, max=3.8, sum=3.8 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=meta_llama-3.1-8b-instruct,model_deployment=huggingface_llama-3.1-8b-instruct"
          ]
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        }
      ],
      [
        {
          "value": "Llama 3.2 Instruct (1.23B)",
          "description": "",
          "markdown": false
        },
        {
          "value": 0.0,
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "value": 1.9000000000000004,
          "description": "min=1.9, mean=1.9, max=1.9, sum=1.9 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=meta_llama-3.2-1b-instruct,model_deployment=huggingface_llama-3.2-1b-instruct"
          ]
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        }
      ],
      [
        {
          "value": "Llama 3.2 Instruct (3B)",
          "description": "",
          "markdown": false
        },
        {
          "value": 0.125,
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "value": 3.3333333333333335,
          "description": "min=3.333, mean=3.333, max=3.333, sum=3.333 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=meta_llama-3.2-3b-instruct,model_deployment=huggingface_llama-3.2-3b-instruct"
          ]
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        }
      ],
      [
        {
          "value": "DeepSeek-R1-0528",
          "description": "",
          "markdown": false
        },
        {
          "value": 0.75,
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "value": 4.433333333333334,
          "description": "min=4.433, mean=4.433, max=4.433, sum=4.433 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:num_output_tokens=4000,model=deepseek-ai_deepseek-r1-0528,model_deployment=together_deepseek-r1-0528"
          ]
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        }
      ],
      [
        {
          "value": "Llama 3.3 Instruct Turbo (70B)",
          "description": "",
          "markdown": false
        },
        {
          "value": 0.5,
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "value": 4.166666666666667,
          "description": "min=4.167, mean=4.167, max=4.167, sum=4.167 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=meta_llama-3.3-70b-instruct-turbo,model_deployment=together_llama-3.3-70b-instruct-turbo"
          ]
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        }
      ],
      [
        {
          "value": "Claude 3.7 Sonnet (20250219)",
          "description": "",
          "markdown": false
        },
        {
          "value": 1.0,
          "style": {
            "font-weight": "bold"
          },
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "value": 4.7,
          "description": "min=4.7, mean=4.7, max=4.7, sum=4.7 (1)",
          "style": {
            "font-weight": "bold"
          },
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=anthropic_claude-3-7-sonnet-20250219,model_deployment=anthropic_claude-3-7-sonnet-20250219"
          ]
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-4.1 (2025-04-14)",
          "description": "",
          "markdown": false
        },
        {
          "value": 0.875,
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "value": 4.533333333333333,
          "description": "min=4.533, mean=4.533, max=4.533, sum=4.533 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=openai_gpt-4.1-2025-04-14,model_deployment=openai_gpt-4.1-2025-04-14"
          ]
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-4.1-mini (2025-04-14)",
          "description": "",
          "markdown": false
        },
        {
          "value": 0.625,
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "value": 4.4,
          "description": "min=4.4, mean=4.4, max=4.4, sum=4.4 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=openai_gpt-4.1-mini-2025-04-14,model_deployment=openai_gpt-4.1-mini-2025-04-14"
          ]
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-4.1-nano (2025-04-14)",
          "description": "",
          "markdown": false
        },
        {
          "value": 0.375,
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "value": 4.1,
          "description": "min=4.1, mean=4.1, max=4.1, sum=4.1 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=openai_gpt-4.1-nano-2025-04-14,model_deployment=openai_gpt-4.1-nano-2025-04-14"
          ]
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "benchmark_output/runs/my-medhelm-suite/groups/latex/clinical_note_generation_accuracy.tex"
      },
      {
        "text": "JSON",
        "href": "benchmark_output/runs/my-medhelm-suite/groups/json/clinical_note_generation_accuracy.json"
      }
    ],
    "name": "accuracy"
  },
  {
    "title": "Efficiency",
    "header": [
      {
        "value": "Model",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "Mean win rate",
        "description": "How many models this model outperforms on average (over columns).",
        "markdown": false,
        "lower_is_better": false,
        "metadata": {}
      },
      {
        "value": "DischargeMe - Observed inference time (s)",
        "description": "DischargeMe is a benchmark designed to evaluate clinical text generation. It pairs discharge summaries and radiology reports from MIMIC-IV with generation tasks such as writing discharge instructions or summarizing the brief hospital course. The benchmark assesses a model's ability to generate patient-facing documentation that is complete, empathetic, and clinically accurate [(Xu, 2024)](https://physionet.org/content/discharge-me/1.3/).\n\nObserved inference runtime (s): Average observed time to process a request to the model (via an API, and thus depends on particular deployment).",
        "markdown": false,
        "lower_is_better": true,
        "metadata": {
          "metric": "Observed inference time (s)",
          "run_group": "DischargeMe"
        }
      },
      {
        "value": "ACI-Bench - Observed inference time (s)",
        "description": "ACI-Bench is a benchmark of real-world patient-doctor conversations paired with structured clinical notes. The benchmark evaluates a model's ability to understand spoken medical dialogue and convert it into formal clinical documentation, covering sections such as history of present illness, physical exam findings, results, and assessment and plan [(Yim et al., 2024)](https://www.nature.com/articles/s41597-023-02487-3).\n\nObserved inference runtime (s): Average observed time to process a request to the model (via an API, and thus depends on particular deployment).",
        "markdown": false,
        "lower_is_better": true,
        "metadata": {
          "metric": "Observed inference time (s)",
          "run_group": "ACI-Bench"
        }
      },
      {
        "value": "MTSamples Procedures - Observed inference time (s)",
        "description": "MTSamples Procedures is a benchmark composed of transcribed operative notes, focused on documenting surgical procedures. Each example presents a brief patient case involving a surgical intervention, and the model is tasked with generating a coherent and clinically accurate procedural summary or treatment plan.\n\nObserved inference runtime (s): Average observed time to process a request to the model (via an API, and thus depends on particular deployment).",
        "markdown": false,
        "lower_is_better": true,
        "metadata": {
          "metric": "Observed inference time (s)",
          "run_group": "MTSamples Procedures"
        }
      },
      {
        "value": "MIMIC-RRS - Observed inference time (s)",
        "description": "MIMIC-RRS is a benchmark constructed from radiology reports in the MIMIC-III database. It contains pairs of \u2018Findings\u2018 and \u2018Impression\u2018 sections, enabling evaluation of a model's ability to summarize diagnostic imaging observations into concise, clinically relevant conclusions [(Chen et al., 2023)](https://arxiv.org/abs/2211.08584).\n\nObserved inference runtime (s): Average observed time to process a request to the model (via an API, and thus depends on particular deployment).",
        "markdown": false,
        "lower_is_better": true,
        "metadata": {
          "metric": "Observed inference time (s)",
          "run_group": "MIMIC-RRS"
        }
      },
      {
        "value": "MIMIC-BHC - Observed inference time (s)",
        "description": "MIMIC-BHC is a benchmark focused on summarization of discharge notes into Brief Hospital Course (BHC) sections. It consists of curated discharge notes from MIMIC-IV, each paired with its corresponding BHC summary. The benchmark evaluates a model's ability to condense detailed clinical information into accurate, concise summaries that reflect the patient's hospital stay [(Aali et al., 2024)](https://doi.org/10.1093/jamia/ocae312).\n\nObserved inference runtime (s): Average observed time to process a request to the model (via an API, and thus depends on particular deployment).",
        "markdown": false,
        "lower_is_better": true,
        "metadata": {
          "metric": "Observed inference time (s)",
          "run_group": "MIMIC-BHC"
        }
      },
      {
        "value": "NoteExtract - Observed inference time (s)",
        "description": "NoteExtract is a benchmark that focuses on the structured extraction of information from free-form clinical text. It provides care plan notes authored by health workers and evaluates a model's ability to convert them into a predefined structured format, such as fields for Chief Complaint and History of Present Illness. The benchmark emphasizes faithful extraction without hallucination or inference.\n\nObserved inference runtime (s): Average observed time to process a request to the model (via an API, and thus depends on particular deployment).",
        "markdown": false,
        "lower_is_better": true,
        "metadata": {
          "metric": "Observed inference time (s)",
          "run_group": "NoteExtract"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "Llama 3.1 Instruct (8B)",
          "description": "",
          "markdown": false
        },
        {
          "value": 0.0,
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "value": 66.88275079727173,
          "description": "min=66.883, mean=66.883, max=66.883, sum=66.883 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=meta_llama-3.1-8b-instruct,model_deployment=huggingface_llama-3.1-8b-instruct"
          ]
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        }
      ],
      [
        {
          "value": "Llama 3.2 Instruct (1.23B)",
          "description": "",
          "markdown": false
        },
        {
          "value": 0.375,
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "value": 19.747730922698974,
          "description": "min=19.748, mean=19.748, max=19.748, sum=19.748 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=meta_llama-3.2-1b-instruct,model_deployment=huggingface_llama-3.2-1b-instruct"
          ]
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        }
      ],
      [
        {
          "value": "Llama 3.2 Instruct (3B)",
          "description": "",
          "markdown": false
        },
        {
          "value": 0.25,
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "value": 51.62401144504547,
          "description": "min=51.624, mean=51.624, max=51.624, sum=51.624 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=meta_llama-3.2-3b-instruct,model_deployment=huggingface_llama-3.2-3b-instruct"
          ]
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        }
      ],
      [
        {
          "value": "DeepSeek-R1-0528",
          "description": "",
          "markdown": false
        },
        {
          "value": 0.5,
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "value": 19.03376421928406,
          "description": "min=19.034, mean=19.034, max=19.034, sum=19.034 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:num_output_tokens=4000,model=deepseek-ai_deepseek-r1-0528,model_deployment=together_deepseek-r1-0528"
          ]
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        }
      ],
      [
        {
          "value": "Llama 3.3 Instruct Turbo (70B)",
          "description": "",
          "markdown": false
        },
        {
          "value": 0.125,
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "value": 64.59834017753602,
          "description": "min=64.598, mean=64.598, max=64.598, sum=64.598 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=meta_llama-3.3-70b-instruct-turbo,model_deployment=together_llama-3.3-70b-instruct-turbo"
          ]
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        }
      ],
      [
        {
          "value": "Claude 3.7 Sonnet (20250219)",
          "description": "",
          "markdown": false
        },
        {
          "value": 0.625,
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "value": 9.940697169303894,
          "description": "min=9.941, mean=9.941, max=9.941, sum=9.941 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=anthropic_claude-3-7-sonnet-20250219,model_deployment=anthropic_claude-3-7-sonnet-20250219"
          ]
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-4.1 (2025-04-14)",
          "description": "",
          "markdown": false
        },
        {
          "value": 0.75,
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "value": 9.810245203971864,
          "description": "min=9.81, mean=9.81, max=9.81, sum=9.81 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=openai_gpt-4.1-2025-04-14,model_deployment=openai_gpt-4.1-2025-04-14"
          ]
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-4.1-mini (2025-04-14)",
          "description": "",
          "markdown": false
        },
        {
          "value": 1.0,
          "style": {
            "font-weight": "bold"
          },
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "value": 6.828373408317566,
          "description": "min=6.828, mean=6.828, max=6.828, sum=6.828 (1)",
          "style": {
            "font-weight": "bold"
          },
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=openai_gpt-4.1-mini-2025-04-14,model_deployment=openai_gpt-4.1-mini-2025-04-14"
          ]
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-4.1-nano (2025-04-14)",
          "description": "",
          "markdown": false
        },
        {
          "value": 0.875,
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "value": 8.015656733512879,
          "description": "min=8.016, mean=8.016, max=8.016, sum=8.016 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=openai_gpt-4.1-nano-2025-04-14,model_deployment=openai_gpt-4.1-nano-2025-04-14"
          ]
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "benchmark_output/runs/my-medhelm-suite/groups/latex/clinical_note_generation_efficiency.tex"
      },
      {
        "text": "JSON",
        "href": "benchmark_output/runs/my-medhelm-suite/groups/json/clinical_note_generation_efficiency.json"
      }
    ],
    "name": "efficiency"
  },
  {
    "title": "General information",
    "header": [
      {
        "value": "Model",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "DischargeMe - # eval",
        "description": "DischargeMe is a benchmark designed to evaluate clinical text generation. It pairs discharge summaries and radiology reports from MIMIC-IV with generation tasks such as writing discharge instructions or summarizing the brief hospital course. The benchmark assesses a model's ability to generate patient-facing documentation that is complete, empathetic, and clinically accurate [(Xu, 2024)](https://physionet.org/content/discharge-me/1.3/).\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "DischargeMe"
        }
      },
      {
        "value": "DischargeMe - # train",
        "description": "DischargeMe is a benchmark designed to evaluate clinical text generation. It pairs discharge summaries and radiology reports from MIMIC-IV with generation tasks such as writing discharge instructions or summarizing the brief hospital course. The benchmark assesses a model's ability to generate patient-facing documentation that is complete, empathetic, and clinically accurate [(Xu, 2024)](https://physionet.org/content/discharge-me/1.3/).\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "DischargeMe"
        }
      },
      {
        "value": "DischargeMe - truncated",
        "description": "DischargeMe is a benchmark designed to evaluate clinical text generation. It pairs discharge summaries and radiology reports from MIMIC-IV with generation tasks such as writing discharge instructions or summarizing the brief hospital course. The benchmark assesses a model's ability to generate patient-facing documentation that is complete, empathetic, and clinically accurate [(Xu, 2024)](https://physionet.org/content/discharge-me/1.3/).\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "DischargeMe"
        }
      },
      {
        "value": "DischargeMe - # prompt tokens",
        "description": "DischargeMe is a benchmark designed to evaluate clinical text generation. It pairs discharge summaries and radiology reports from MIMIC-IV with generation tasks such as writing discharge instructions or summarizing the brief hospital course. The benchmark assesses a model's ability to generate patient-facing documentation that is complete, empathetic, and clinically accurate [(Xu, 2024)](https://physionet.org/content/discharge-me/1.3/).\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "DischargeMe"
        }
      },
      {
        "value": "DischargeMe - # output tokens",
        "description": "DischargeMe is a benchmark designed to evaluate clinical text generation. It pairs discharge summaries and radiology reports from MIMIC-IV with generation tasks such as writing discharge instructions or summarizing the brief hospital course. The benchmark assesses a model's ability to generate patient-facing documentation that is complete, empathetic, and clinically accurate [(Xu, 2024)](https://physionet.org/content/discharge-me/1.3/).\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "DischargeMe"
        }
      },
      {
        "value": "ACI-Bench - # eval",
        "description": "ACI-Bench is a benchmark of real-world patient-doctor conversations paired with structured clinical notes. The benchmark evaluates a model's ability to understand spoken medical dialogue and convert it into formal clinical documentation, covering sections such as history of present illness, physical exam findings, results, and assessment and plan [(Yim et al., 2024)](https://www.nature.com/articles/s41597-023-02487-3).\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "ACI-Bench"
        }
      },
      {
        "value": "ACI-Bench - # train",
        "description": "ACI-Bench is a benchmark of real-world patient-doctor conversations paired with structured clinical notes. The benchmark evaluates a model's ability to understand spoken medical dialogue and convert it into formal clinical documentation, covering sections such as history of present illness, physical exam findings, results, and assessment and plan [(Yim et al., 2024)](https://www.nature.com/articles/s41597-023-02487-3).\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "ACI-Bench"
        }
      },
      {
        "value": "ACI-Bench - truncated",
        "description": "ACI-Bench is a benchmark of real-world patient-doctor conversations paired with structured clinical notes. The benchmark evaluates a model's ability to understand spoken medical dialogue and convert it into formal clinical documentation, covering sections such as history of present illness, physical exam findings, results, and assessment and plan [(Yim et al., 2024)](https://www.nature.com/articles/s41597-023-02487-3).\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "ACI-Bench"
        }
      },
      {
        "value": "ACI-Bench - # prompt tokens",
        "description": "ACI-Bench is a benchmark of real-world patient-doctor conversations paired with structured clinical notes. The benchmark evaluates a model's ability to understand spoken medical dialogue and convert it into formal clinical documentation, covering sections such as history of present illness, physical exam findings, results, and assessment and plan [(Yim et al., 2024)](https://www.nature.com/articles/s41597-023-02487-3).\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "ACI-Bench"
        }
      },
      {
        "value": "ACI-Bench - # output tokens",
        "description": "ACI-Bench is a benchmark of real-world patient-doctor conversations paired with structured clinical notes. The benchmark evaluates a model's ability to understand spoken medical dialogue and convert it into formal clinical documentation, covering sections such as history of present illness, physical exam findings, results, and assessment and plan [(Yim et al., 2024)](https://www.nature.com/articles/s41597-023-02487-3).\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "ACI-Bench"
        }
      },
      {
        "value": "MTSamples Procedures - # eval",
        "description": "MTSamples Procedures is a benchmark composed of transcribed operative notes, focused on documenting surgical procedures. Each example presents a brief patient case involving a surgical intervention, and the model is tasked with generating a coherent and clinically accurate procedural summary or treatment plan.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "MTSamples Procedures"
        }
      },
      {
        "value": "MTSamples Procedures - # train",
        "description": "MTSamples Procedures is a benchmark composed of transcribed operative notes, focused on documenting surgical procedures. Each example presents a brief patient case involving a surgical intervention, and the model is tasked with generating a coherent and clinically accurate procedural summary or treatment plan.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "MTSamples Procedures"
        }
      },
      {
        "value": "MTSamples Procedures - truncated",
        "description": "MTSamples Procedures is a benchmark composed of transcribed operative notes, focused on documenting surgical procedures. Each example presents a brief patient case involving a surgical intervention, and the model is tasked with generating a coherent and clinically accurate procedural summary or treatment plan.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "MTSamples Procedures"
        }
      },
      {
        "value": "MTSamples Procedures - # prompt tokens",
        "description": "MTSamples Procedures is a benchmark composed of transcribed operative notes, focused on documenting surgical procedures. Each example presents a brief patient case involving a surgical intervention, and the model is tasked with generating a coherent and clinically accurate procedural summary or treatment plan.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "MTSamples Procedures"
        }
      },
      {
        "value": "MTSamples Procedures - # output tokens",
        "description": "MTSamples Procedures is a benchmark composed of transcribed operative notes, focused on documenting surgical procedures. Each example presents a brief patient case involving a surgical intervention, and the model is tasked with generating a coherent and clinically accurate procedural summary or treatment plan.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "MTSamples Procedures"
        }
      },
      {
        "value": "MIMIC-RRS - # eval",
        "description": "MIMIC-RRS is a benchmark constructed from radiology reports in the MIMIC-III database. It contains pairs of \u2018Findings\u2018 and \u2018Impression\u2018 sections, enabling evaluation of a model's ability to summarize diagnostic imaging observations into concise, clinically relevant conclusions [(Chen et al., 2023)](https://arxiv.org/abs/2211.08584).\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "MIMIC-RRS"
        }
      },
      {
        "value": "MIMIC-RRS - # train",
        "description": "MIMIC-RRS is a benchmark constructed from radiology reports in the MIMIC-III database. It contains pairs of \u2018Findings\u2018 and \u2018Impression\u2018 sections, enabling evaluation of a model's ability to summarize diagnostic imaging observations into concise, clinically relevant conclusions [(Chen et al., 2023)](https://arxiv.org/abs/2211.08584).\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "MIMIC-RRS"
        }
      },
      {
        "value": "MIMIC-RRS - truncated",
        "description": "MIMIC-RRS is a benchmark constructed from radiology reports in the MIMIC-III database. It contains pairs of \u2018Findings\u2018 and \u2018Impression\u2018 sections, enabling evaluation of a model's ability to summarize diagnostic imaging observations into concise, clinically relevant conclusions [(Chen et al., 2023)](https://arxiv.org/abs/2211.08584).\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "MIMIC-RRS"
        }
      },
      {
        "value": "MIMIC-RRS - # prompt tokens",
        "description": "MIMIC-RRS is a benchmark constructed from radiology reports in the MIMIC-III database. It contains pairs of \u2018Findings\u2018 and \u2018Impression\u2018 sections, enabling evaluation of a model's ability to summarize diagnostic imaging observations into concise, clinically relevant conclusions [(Chen et al., 2023)](https://arxiv.org/abs/2211.08584).\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "MIMIC-RRS"
        }
      },
      {
        "value": "MIMIC-RRS - # output tokens",
        "description": "MIMIC-RRS is a benchmark constructed from radiology reports in the MIMIC-III database. It contains pairs of \u2018Findings\u2018 and \u2018Impression\u2018 sections, enabling evaluation of a model's ability to summarize diagnostic imaging observations into concise, clinically relevant conclusions [(Chen et al., 2023)](https://arxiv.org/abs/2211.08584).\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "MIMIC-RRS"
        }
      },
      {
        "value": "MIMIC-BHC - # eval",
        "description": "MIMIC-BHC is a benchmark focused on summarization of discharge notes into Brief Hospital Course (BHC) sections. It consists of curated discharge notes from MIMIC-IV, each paired with its corresponding BHC summary. The benchmark evaluates a model's ability to condense detailed clinical information into accurate, concise summaries that reflect the patient's hospital stay [(Aali et al., 2024)](https://doi.org/10.1093/jamia/ocae312).\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "MIMIC-BHC"
        }
      },
      {
        "value": "MIMIC-BHC - # train",
        "description": "MIMIC-BHC is a benchmark focused on summarization of discharge notes into Brief Hospital Course (BHC) sections. It consists of curated discharge notes from MIMIC-IV, each paired with its corresponding BHC summary. The benchmark evaluates a model's ability to condense detailed clinical information into accurate, concise summaries that reflect the patient's hospital stay [(Aali et al., 2024)](https://doi.org/10.1093/jamia/ocae312).\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "MIMIC-BHC"
        }
      },
      {
        "value": "MIMIC-BHC - truncated",
        "description": "MIMIC-BHC is a benchmark focused on summarization of discharge notes into Brief Hospital Course (BHC) sections. It consists of curated discharge notes from MIMIC-IV, each paired with its corresponding BHC summary. The benchmark evaluates a model's ability to condense detailed clinical information into accurate, concise summaries that reflect the patient's hospital stay [(Aali et al., 2024)](https://doi.org/10.1093/jamia/ocae312).\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "MIMIC-BHC"
        }
      },
      {
        "value": "MIMIC-BHC - # prompt tokens",
        "description": "MIMIC-BHC is a benchmark focused on summarization of discharge notes into Brief Hospital Course (BHC) sections. It consists of curated discharge notes from MIMIC-IV, each paired with its corresponding BHC summary. The benchmark evaluates a model's ability to condense detailed clinical information into accurate, concise summaries that reflect the patient's hospital stay [(Aali et al., 2024)](https://doi.org/10.1093/jamia/ocae312).\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "MIMIC-BHC"
        }
      },
      {
        "value": "MIMIC-BHC - # output tokens",
        "description": "MIMIC-BHC is a benchmark focused on summarization of discharge notes into Brief Hospital Course (BHC) sections. It consists of curated discharge notes from MIMIC-IV, each paired with its corresponding BHC summary. The benchmark evaluates a model's ability to condense detailed clinical information into accurate, concise summaries that reflect the patient's hospital stay [(Aali et al., 2024)](https://doi.org/10.1093/jamia/ocae312).\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "MIMIC-BHC"
        }
      },
      {
        "value": "NoteExtract - # eval",
        "description": "NoteExtract is a benchmark that focuses on the structured extraction of information from free-form clinical text. It provides care plan notes authored by health workers and evaluates a model's ability to convert them into a predefined structured format, such as fields for Chief Complaint and History of Present Illness. The benchmark emphasizes faithful extraction without hallucination or inference.\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "NoteExtract"
        }
      },
      {
        "value": "NoteExtract - # train",
        "description": "NoteExtract is a benchmark that focuses on the structured extraction of information from free-form clinical text. It provides care plan notes authored by health workers and evaluates a model's ability to convert them into a predefined structured format, such as fields for Chief Complaint and History of Present Illness. The benchmark emphasizes faithful extraction without hallucination or inference.\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "NoteExtract"
        }
      },
      {
        "value": "NoteExtract - truncated",
        "description": "NoteExtract is a benchmark that focuses on the structured extraction of information from free-form clinical text. It provides care plan notes authored by health workers and evaluates a model's ability to convert them into a predefined structured format, such as fields for Chief Complaint and History of Present Illness. The benchmark emphasizes faithful extraction without hallucination or inference.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "NoteExtract"
        }
      },
      {
        "value": "NoteExtract - # prompt tokens",
        "description": "NoteExtract is a benchmark that focuses on the structured extraction of information from free-form clinical text. It provides care plan notes authored by health workers and evaluates a model's ability to convert them into a predefined structured format, such as fields for Chief Complaint and History of Present Illness. The benchmark emphasizes faithful extraction without hallucination or inference.\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "NoteExtract"
        }
      },
      {
        "value": "NoteExtract - # output tokens",
        "description": "NoteExtract is a benchmark that focuses on the structured extraction of information from free-form clinical text. It provides care plan notes authored by health workers and evaluates a model's ability to convert them into a predefined structured format, such as fields for Chief Complaint and History of Present Illness. The benchmark emphasizes faithful extraction without hallucination or inference.\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "NoteExtract"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "Llama 3.1 Instruct (8B)",
          "description": "",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=meta_llama-3.1-8b-instruct,model_deployment=huggingface_llama-3.1-8b-instruct"
          ]
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=meta_llama-3.1-8b-instruct,model_deployment=huggingface_llama-3.1-8b-instruct"
          ]
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=meta_llama-3.1-8b-instruct,model_deployment=huggingface_llama-3.1-8b-instruct"
          ]
        },
        {
          "value": 1447.3,
          "description": "min=1447.3, mean=1447.3, max=1447.3, sum=1447.3 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=meta_llama-3.1-8b-instruct,model_deployment=huggingface_llama-3.1-8b-instruct"
          ]
        },
        {
          "value": 402.6,
          "description": "min=402.6, mean=402.6, max=402.6, sum=402.6 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=meta_llama-3.1-8b-instruct,model_deployment=huggingface_llama-3.1-8b-instruct"
          ]
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        }
      ],
      [
        {
          "value": "Llama 3.2 Instruct (1.23B)",
          "description": "",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=meta_llama-3.2-1b-instruct,model_deployment=huggingface_llama-3.2-1b-instruct"
          ]
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=meta_llama-3.2-1b-instruct,model_deployment=huggingface_llama-3.2-1b-instruct"
          ]
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=meta_llama-3.2-1b-instruct,model_deployment=huggingface_llama-3.2-1b-instruct"
          ]
        },
        {
          "value": 1447.3,
          "description": "min=1447.3, mean=1447.3, max=1447.3, sum=1447.3 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=meta_llama-3.2-1b-instruct,model_deployment=huggingface_llama-3.2-1b-instruct"
          ]
        },
        {
          "value": 221.7,
          "description": "min=221.7, mean=221.7, max=221.7, sum=221.7 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=meta_llama-3.2-1b-instruct,model_deployment=huggingface_llama-3.2-1b-instruct"
          ]
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        }
      ],
      [
        {
          "value": "Llama 3.2 Instruct (3B)",
          "description": "",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=meta_llama-3.2-3b-instruct,model_deployment=huggingface_llama-3.2-3b-instruct"
          ]
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=meta_llama-3.2-3b-instruct,model_deployment=huggingface_llama-3.2-3b-instruct"
          ]
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=meta_llama-3.2-3b-instruct,model_deployment=huggingface_llama-3.2-3b-instruct"
          ]
        },
        {
          "value": 1447.3,
          "description": "min=1447.3, mean=1447.3, max=1447.3, sum=1447.3 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=meta_llama-3.2-3b-instruct,model_deployment=huggingface_llama-3.2-3b-instruct"
          ]
        },
        {
          "value": 362.4,
          "description": "min=362.4, mean=362.4, max=362.4, sum=362.4 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=meta_llama-3.2-3b-instruct,model_deployment=huggingface_llama-3.2-3b-instruct"
          ]
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        }
      ],
      [
        {
          "value": "DeepSeek-R1-0528",
          "description": "",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:num_output_tokens=4000,model=deepseek-ai_deepseek-r1-0528,model_deployment=together_deepseek-r1-0528"
          ]
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:num_output_tokens=4000,model=deepseek-ai_deepseek-r1-0528,model_deployment=together_deepseek-r1-0528"
          ]
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:num_output_tokens=4000,model=deepseek-ai_deepseek-r1-0528,model_deployment=together_deepseek-r1-0528"
          ]
        },
        {
          "value": 1433.1,
          "description": "min=1433.1, mean=1433.1, max=1433.1, sum=1433.1 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:num_output_tokens=4000,model=deepseek-ai_deepseek-r1-0528,model_deployment=together_deepseek-r1-0528"
          ]
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:num_output_tokens=4000,model=deepseek-ai_deepseek-r1-0528,model_deployment=together_deepseek-r1-0528"
          ]
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        }
      ],
      [
        {
          "value": "Llama 3.3 Instruct Turbo (70B)",
          "description": "",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=meta_llama-3.3-70b-instruct-turbo,model_deployment=together_llama-3.3-70b-instruct-turbo"
          ]
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=meta_llama-3.3-70b-instruct-turbo,model_deployment=together_llama-3.3-70b-instruct-turbo"
          ]
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=meta_llama-3.3-70b-instruct-turbo,model_deployment=together_llama-3.3-70b-instruct-turbo"
          ]
        },
        {
          "value": 1447.3,
          "description": "min=1447.3, mean=1447.3, max=1447.3, sum=1447.3 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=meta_llama-3.3-70b-instruct-turbo,model_deployment=together_llama-3.3-70b-instruct-turbo"
          ]
        },
        {
          "value": 400.8,
          "description": "min=400.8, mean=400.8, max=400.8, sum=400.8 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=meta_llama-3.3-70b-instruct-turbo,model_deployment=together_llama-3.3-70b-instruct-turbo"
          ]
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        }
      ],
      [
        {
          "value": "Claude 3.7 Sonnet (20250219)",
          "description": "",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=anthropic_claude-3-7-sonnet-20250219,model_deployment=anthropic_claude-3-7-sonnet-20250219"
          ]
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=anthropic_claude-3-7-sonnet-20250219,model_deployment=anthropic_claude-3-7-sonnet-20250219"
          ]
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=anthropic_claude-3-7-sonnet-20250219,model_deployment=anthropic_claude-3-7-sonnet-20250219"
          ]
        },
        {
          "value": 1515.8,
          "description": "min=1515.8, mean=1515.8, max=1515.8, sum=1515.8 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=anthropic_claude-3-7-sonnet-20250219,model_deployment=anthropic_claude-3-7-sonnet-20250219"
          ]
        },
        {
          "value": 413.8,
          "description": "min=413.8, mean=413.8, max=413.8, sum=413.8 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=anthropic_claude-3-7-sonnet-20250219,model_deployment=anthropic_claude-3-7-sonnet-20250219"
          ]
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-4.1 (2025-04-14)",
          "description": "",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=openai_gpt-4.1-2025-04-14,model_deployment=openai_gpt-4.1-2025-04-14"
          ]
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=openai_gpt-4.1-2025-04-14,model_deployment=openai_gpt-4.1-2025-04-14"
          ]
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=openai_gpt-4.1-2025-04-14,model_deployment=openai_gpt-4.1-2025-04-14"
          ]
        },
        {
          "value": 1399.9,
          "description": "min=1399.9, mean=1399.9, max=1399.9, sum=1399.9 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=openai_gpt-4.1-2025-04-14,model_deployment=openai_gpt-4.1-2025-04-14"
          ]
        },
        {
          "value": 480.4,
          "description": "min=480.4, mean=480.4, max=480.4, sum=480.4 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=openai_gpt-4.1-2025-04-14,model_deployment=openai_gpt-4.1-2025-04-14"
          ]
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-4.1-mini (2025-04-14)",
          "description": "",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=openai_gpt-4.1-mini-2025-04-14,model_deployment=openai_gpt-4.1-mini-2025-04-14"
          ]
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=openai_gpt-4.1-mini-2025-04-14,model_deployment=openai_gpt-4.1-mini-2025-04-14"
          ]
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=openai_gpt-4.1-mini-2025-04-14,model_deployment=openai_gpt-4.1-mini-2025-04-14"
          ]
        },
        {
          "value": 1399.9,
          "description": "min=1399.9, mean=1399.9, max=1399.9, sum=1399.9 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=openai_gpt-4.1-mini-2025-04-14,model_deployment=openai_gpt-4.1-mini-2025-04-14"
          ]
        },
        {
          "value": 403.8,
          "description": "min=403.8, mean=403.8, max=403.8, sum=403.8 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=openai_gpt-4.1-mini-2025-04-14,model_deployment=openai_gpt-4.1-mini-2025-04-14"
          ]
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-4.1-nano (2025-04-14)",
          "description": "",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "value": 10.0,
          "description": "min=10, mean=10, max=10, sum=10 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=openai_gpt-4.1-nano-2025-04-14,model_deployment=openai_gpt-4.1-nano-2025-04-14"
          ]
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=openai_gpt-4.1-nano-2025-04-14,model_deployment=openai_gpt-4.1-nano-2025-04-14"
          ]
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=openai_gpt-4.1-nano-2025-04-14,model_deployment=openai_gpt-4.1-nano-2025-04-14"
          ]
        },
        {
          "value": 1399.9,
          "description": "min=1399.9, mean=1399.9, max=1399.9, sum=1399.9 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=openai_gpt-4.1-nano-2025-04-14,model_deployment=openai_gpt-4.1-nano-2025-04-14"
          ]
        },
        {
          "value": 387.5,
          "description": "min=387.5, mean=387.5, max=387.5, sum=387.5 (1)",
          "style": {},
          "markdown": false,
          "run_spec_names": [
            "aci_bench:model=openai_gpt-4.1-nano-2025-04-14,model_deployment=openai_gpt-4.1-nano-2025-04-14"
          ]
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        },
        {
          "description": "No matching runs",
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "benchmark_output/runs/my-medhelm-suite/groups/latex/clinical_note_generation_general_information.tex"
      },
      {
        "text": "JSON",
        "href": "benchmark_output/runs/my-medhelm-suite/groups/json/clinical_note_generation_general_information.json"
      }
    ],
    "name": "general_information"
  }
]