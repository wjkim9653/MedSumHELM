{
  "title": "",
  "header": [
    {
      "value": "Model",
      "markdown": false,
      "metadata": {}
    },
    {
      "value": "Jury Score",
      "description": "ACI-Bench is a benchmark of real-world patient-doctor conversations paired with structured clinical notes. The benchmark evaluates a model's ability to understand spoken medical dialogue and convert it into formal clinical documentation, covering sections such as history of present illness, physical exam findings, results, and assessment and plan [(Yim et al., 2024)](https://www.nature.com/articles/s41597-023-02487-3).\n\nACI-Bench Jury Score: Measures the average score assigned by an LLM-based jury evaluating task performance.",
      "markdown": false,
      "lower_is_better": false,
      "metadata": {
        "metric": "Jury Score",
        "run_group": "ACI-Bench"
      }
    },
    {
      "value": "Observed inference time (s)",
      "description": "ACI-Bench is a benchmark of real-world patient-doctor conversations paired with structured clinical notes. The benchmark evaluates a model's ability to understand spoken medical dialogue and convert it into formal clinical documentation, covering sections such as history of present illness, physical exam findings, results, and assessment and plan [(Yim et al., 2024)](https://www.nature.com/articles/s41597-023-02487-3).\n\nObserved inference runtime (s): Average observed time to process a request to the model (via an API, and thus depends on particular deployment).",
      "markdown": false,
      "lower_is_better": true,
      "metadata": {
        "metric": "Observed inference time (s)",
        "run_group": "ACI-Bench"
      }
    },
    {
      "value": "# eval",
      "description": "ACI-Bench is a benchmark of real-world patient-doctor conversations paired with structured clinical notes. The benchmark evaluates a model's ability to understand spoken medical dialogue and convert it into formal clinical documentation, covering sections such as history of present illness, physical exam findings, results, and assessment and plan [(Yim et al., 2024)](https://www.nature.com/articles/s41597-023-02487-3).\n\n# eval: Number of evaluation instances.",
      "markdown": false,
      "metadata": {
        "metric": "# eval",
        "run_group": "ACI-Bench"
      }
    },
    {
      "value": "# train",
      "description": "ACI-Bench is a benchmark of real-world patient-doctor conversations paired with structured clinical notes. The benchmark evaluates a model's ability to understand spoken medical dialogue and convert it into formal clinical documentation, covering sections such as history of present illness, physical exam findings, results, and assessment and plan [(Yim et al., 2024)](https://www.nature.com/articles/s41597-023-02487-3).\n\n# train: Number of training instances (e.g., in-context examples).",
      "markdown": false,
      "metadata": {
        "metric": "# train",
        "run_group": "ACI-Bench"
      }
    },
    {
      "value": "truncated",
      "description": "ACI-Bench is a benchmark of real-world patient-doctor conversations paired with structured clinical notes. The benchmark evaluates a model's ability to understand spoken medical dialogue and convert it into formal clinical documentation, covering sections such as history of present illness, physical exam findings, results, and assessment and plan [(Yim et al., 2024)](https://www.nature.com/articles/s41597-023-02487-3).\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
      "markdown": false,
      "metadata": {
        "metric": "truncated",
        "run_group": "ACI-Bench"
      }
    },
    {
      "value": "# prompt tokens",
      "description": "ACI-Bench is a benchmark of real-world patient-doctor conversations paired with structured clinical notes. The benchmark evaluates a model's ability to understand spoken medical dialogue and convert it into formal clinical documentation, covering sections such as history of present illness, physical exam findings, results, and assessment and plan [(Yim et al., 2024)](https://www.nature.com/articles/s41597-023-02487-3).\n\n# prompt tokens: Number of tokens in the prompt.",
      "markdown": false,
      "metadata": {
        "metric": "# prompt tokens",
        "run_group": "ACI-Bench"
      }
    },
    {
      "value": "# output tokens",
      "description": "ACI-Bench is a benchmark of real-world patient-doctor conversations paired with structured clinical notes. The benchmark evaluates a model's ability to understand spoken medical dialogue and convert it into formal clinical documentation, covering sections such as history of present illness, physical exam findings, results, and assessment and plan [(Yim et al., 2024)](https://www.nature.com/articles/s41597-023-02487-3).\n\n# output tokens: Actual number of output tokens.",
      "markdown": false,
      "metadata": {
        "metric": "# output tokens",
        "run_group": "ACI-Bench"
      }
    }
  ],
  "rows": [
    [
      {
        "value": "Llama 3.1 Instruct (8B)",
        "description": "",
        "href": "?group=aci_bench&subgroup=&runSpecs=%5B%22aci_bench%3Amodel%3Dmeta_llama-3.1-8b-instruct%2Cmodel_deployment%3Dhuggingface_llama-3.1-8b-instruct%22%5D",
        "markdown": false,
        "run_spec_names": [
          "aci_bench:model=meta_llama-3.1-8b-instruct,model_deployment=huggingface_llama-3.1-8b-instruct"
        ]
      },
      {
        "value": 3.719444444444443,
        "description": "min=3.719, mean=3.719, max=3.719, sum=3.719 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 75.93968614141146,
        "description": "min=75.94, mean=75.94, max=75.94, sum=75.94 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 120.0,
        "description": "min=120, mean=120, max=120, sum=120 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1629.5833333333333,
        "description": "min=1629.583, mean=1629.583, max=1629.583, sum=1629.583 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 429.0833333333333,
        "description": "min=429.083, mean=429.083, max=429.083, sum=429.083 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "Llama 3.2 Instruct (1.23B)",
        "description": "",
        "href": "?group=aci_bench&subgroup=&runSpecs=%5B%22aci_bench%3Amodel%3Dmeta_llama-3.2-1b-instruct%2Cmodel_deployment%3Dhuggingface_llama-3.2-1b-instruct%22%5D",
        "markdown": false,
        "run_spec_names": [
          "aci_bench:model=meta_llama-3.2-1b-instruct,model_deployment=huggingface_llama-3.2-1b-instruct"
        ]
      },
      {
        "value": 1.9333333333333336,
        "description": "min=1.933, mean=1.933, max=1.933, sum=1.933 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 11.21833381652832,
        "description": "min=11.218, mean=11.218, max=11.218, sum=11.218 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1447.3,
        "description": "min=1447.3, mean=1447.3, max=1447.3, sum=1447.3 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 216.0,
        "description": "min=216, mean=216, max=216, sum=216 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "Llama 3.2 Instruct (3B)",
        "description": "",
        "href": "?group=aci_bench&subgroup=&runSpecs=%5B%22aci_bench%3Amodel%3Dmeta_llama-3.2-3b-instruct%2Cmodel_deployment%3Dhuggingface_llama-3.2-3b-instruct%22%5D",
        "markdown": false,
        "run_spec_names": [
          "aci_bench:model=meta_llama-3.2-3b-instruct,model_deployment=huggingface_llama-3.2-3b-instruct"
        ]
      },
      {
        "value": 3.244444444444444,
        "description": "min=3.244, mean=3.244, max=3.244, sum=3.244 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 59.51362446546555,
        "description": "min=59.514, mean=59.514, max=59.514, sum=59.514 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 120.0,
        "description": "min=120, mean=120, max=120, sum=120 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1629.5833333333333,
        "description": "min=1629.583, mean=1629.583, max=1629.583, sum=1629.583 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 391.3833333333333,
        "description": "min=391.383, mean=391.383, max=391.383, sum=391.383 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "DeepSeek-R1-0528",
        "description": "",
        "href": "?group=aci_bench&subgroup=&runSpecs=%5B%22aci_bench%3Anum_output_tokens%3D4000%2Cmodel%3Ddeepseek-ai_deepseek-r1-0528%2Cmodel_deployment%3Dtogether_deepseek-r1-0528%22%5D",
        "markdown": false,
        "run_spec_names": [
          "aci_bench:num_output_tokens=4000,model=deepseek-ai_deepseek-r1-0528,model_deployment=together_deepseek-r1-0528"
        ]
      },
      {
        "value": 4.419444444444446,
        "description": "min=4.419, mean=4.419, max=4.419, sum=4.419 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 18.903887156645457,
        "description": "min=18.904, mean=18.904, max=18.904, sum=18.904 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 120.0,
        "description": "min=120, mean=120, max=120, sum=120 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1613.1666666666667,
        "description": "min=1613.167, mean=1613.167, max=1613.167, sum=1613.167 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "Llama 3.3 Instruct Turbo (70B)",
        "description": "",
        "href": "?group=aci_bench&subgroup=&runSpecs=%5B%22aci_bench%3Amodel%3Dmeta_llama-3.3-70b-instruct-turbo%2Cmodel_deployment%3Dtogether_llama-3.3-70b-instruct-turbo%22%5D",
        "markdown": false,
        "run_spec_names": [
          "aci_bench:model=meta_llama-3.3-70b-instruct-turbo,model_deployment=together_llama-3.3-70b-instruct-turbo"
        ]
      },
      {
        "value": 4.050000000000001,
        "description": "min=4.05, mean=4.05, max=4.05, sum=4.05 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 29.972085070610046,
        "description": "min=29.972, mean=29.972, max=29.972, sum=29.972 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 120.0,
        "description": "min=120, mean=120, max=120, sum=120 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1629.5833333333333,
        "description": "min=1629.583, mean=1629.583, max=1629.583, sum=1629.583 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 429.7416666666667,
        "description": "min=429.742, mean=429.742, max=429.742, sum=429.742 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "Claude 3.7 Sonnet (20250219)",
        "description": "",
        "href": "?group=aci_bench&subgroup=&runSpecs=%5B%22aci_bench%3Amodel%3Danthropic_claude-3-7-sonnet-20250219%2Cmodel_deployment%3Danthropic_claude-3-7-sonnet-20250219%22%5D",
        "markdown": false,
        "run_spec_names": [
          "aci_bench:model=anthropic_claude-3-7-sonnet-20250219,model_deployment=anthropic_claude-3-7-sonnet-20250219"
        ]
      },
      {
        "value": 4.547222222222223,
        "description": "min=4.547, mean=4.547, max=4.547, sum=4.547 (1)",
        "style": {
          "font-weight": "bold"
        },
        "markdown": false
      },
      {
        "value": 16.05382503668467,
        "description": "min=16.054, mean=16.054, max=16.054, sum=16.054 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 120.0,
        "description": "min=120, mean=120, max=120, sum=120 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1674.0583333333334,
        "description": "min=1674.058, mean=1674.058, max=1674.058, sum=1674.058 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 455.95,
        "description": "min=455.95, mean=455.95, max=455.95, sum=455.95 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "GPT-4.1 (2025-04-14)",
        "description": "",
        "href": "?group=aci_bench&subgroup=&runSpecs=%5B%22aci_bench%3Amodel%3Dopenai_gpt-4.1-2025-04-14%2Cmodel_deployment%3Dopenai_gpt-4.1-2025-04-14%22%5D",
        "markdown": false,
        "run_spec_names": [
          "aci_bench:model=openai_gpt-4.1-2025-04-14,model_deployment=openai_gpt-4.1-2025-04-14"
        ]
      },
      {
        "value": 4.477777777777777,
        "description": "min=4.478, mean=4.478, max=4.478, sum=4.478 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 13.234592833121617,
        "description": "min=13.235, mean=13.235, max=13.235, sum=13.235 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 120.0,
        "description": "min=120, mean=120, max=120, sum=120 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1573.6416666666667,
        "description": "min=1573.642, mean=1573.642, max=1573.642, sum=1573.642 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 511.8333333333333,
        "description": "min=511.833, mean=511.833, max=511.833, sum=511.833 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "GPT-4.1-mini (2025-04-14)",
        "description": "",
        "href": "?group=aci_bench&subgroup=&runSpecs=%5B%22aci_bench%3Amodel%3Dopenai_gpt-4.1-mini-2025-04-14%2Cmodel_deployment%3Dopenai_gpt-4.1-mini-2025-04-14%22%5D",
        "markdown": false,
        "run_spec_names": [
          "aci_bench:model=openai_gpt-4.1-mini-2025-04-14,model_deployment=openai_gpt-4.1-mini-2025-04-14"
        ]
      },
      {
        "value": 4.366666666666666,
        "description": "min=4.367, mean=4.367, max=4.367, sum=4.367 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 8.03999240597089,
        "description": "min=8.04, mean=8.04, max=8.04, sum=8.04 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 120.0,
        "description": "min=120, mean=120, max=120, sum=120 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1573.6416666666667,
        "description": "min=1573.642, mean=1573.642, max=1573.642, sum=1573.642 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 435.7916666666667,
        "description": "min=435.792, mean=435.792, max=435.792, sum=435.792 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "GPT-4.1-nano (2025-04-14)",
        "description": "",
        "href": "?group=aci_bench&subgroup=&runSpecs=%5B%22aci_bench%3Amodel%3Dopenai_gpt-4.1-nano-2025-04-14%2Cmodel_deployment%3Dopenai_gpt-4.1-nano-2025-04-14%22%5D",
        "markdown": false,
        "run_spec_names": [
          "aci_bench:model=openai_gpt-4.1-nano-2025-04-14,model_deployment=openai_gpt-4.1-nano-2025-04-14"
        ]
      },
      {
        "value": 4.099999999999998,
        "description": "min=4.1, mean=4.1, max=4.1, sum=4.1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 5.970380202929179,
        "description": "min=5.97, mean=5.97, max=5.97, sum=5.97 (1)",
        "style": {
          "font-weight": "bold"
        },
        "markdown": false
      },
      {
        "value": 120.0,
        "description": "min=120, mean=120, max=120, sum=120 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1573.6416666666667,
        "description": "min=1573.642, mean=1573.642, max=1573.642, sum=1573.642 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 426.6666666666667,
        "description": "min=426.667, mean=426.667, max=426.667, sum=426.667 (1)",
        "style": {},
        "markdown": false
      }
    ]
  ],
  "links": [
    {
      "text": "LaTeX",
      "href": "benchmark_output/runs/my-medhelm-suite/groups/latex/aci_bench_aci_bench_.tex"
    },
    {
      "text": "JSON",
      "href": "benchmark_output/runs/my-medhelm-suite/groups/json/aci_bench_aci_bench_.json"
    }
  ],
  "name": "aci_bench_"
}